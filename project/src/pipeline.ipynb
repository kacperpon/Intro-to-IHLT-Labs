{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Semantic Textual Similarity Project\n",
    "\n",
    "**Authors**\n",
    "- Kacper Poniatowski\n",
    "- Pau Blanco\n",
    "\n",
    "TODO: Include brief outline of project\n",
    "- Context\n",
    "- What were trying to achieve\n",
    "- etc."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pre-Reqs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\Kacpe\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package averaged_perceptron_tagger_eng to\n",
      "[nltk_data]     C:\\Users\\Kacpe\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package averaged_perceptron_tagger_eng is already up-to-\n",
      "[nltk_data]       date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\Kacpe\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package punkt_tab to\n",
      "[nltk_data]     C:\\Users\\Kacpe\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt_tab is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\Kacpe\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet_ic to\n",
      "[nltk_data]     C:\\Users\\Kacpe\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet_ic is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Force auto-reload\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import pandas as pd\n",
    "import nltk\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "from utils import load_data, evaluate_rf_model, drop_highly_correlated_features\n",
    "from models import ModelTrainer\n",
    "from feature_extraction import FeatureExtractor\n",
    "from utils import save_predictions\n",
    "from scipy.stats import pearsonr\n",
    "\n",
    "nltk.download('punkt')\n",
    "nltk.download('averaged_perceptron_tagger_eng')\n",
    "nltk.download('wordnet')\n",
    "nltk.download('punkt_tab')\n",
    "nltk.download('stopwords')\n",
    "nltk.download('wordnet_ic')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define Constants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define constant paths used throughout notebook\n",
    "TRAIN_PATH = '../data/train/01_raw/'\n",
    "TRAIN_GS_PATH = '../data/train/scores/'\n",
    "TEST_PATH = '../data/test/01_raw/'\n",
    "TEST_GS_PATH = '../data/test/scores/'\n",
    "TRAIN_SAVE_PATH = '../data/train/02_preprocessed/preprocessed_train_data.csv'\n",
    "TEST_SAVE_PATH = '../data/test/02_preprocessed/preprocessed_test_data.csv'\n",
    "PREDICTED_SAVE_PATH = '../data/test/03_predicted/'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Loading train data\n",
      "\n",
      " Loading test data\n",
      "\n",
      " Train and test datasets loaded successfully\n"
     ]
    }
   ],
   "source": [
    "# Load train data\n",
    "print('\\n Loading train data')\n",
    "all_train_files = ['SMTeuroparl', 'MSRvid', 'MSRpar']\n",
    "df_train = load_data(TRAIN_PATH, TRAIN_GS_PATH, all_train_files)\n",
    "\n",
    "# Load test data\n",
    "print('\\n Loading test data')\n",
    "all_test_files = ['SMTeuroparl', 'MSRvid', 'MSRpar', 'surprise.OnWN', 'surprise.SMTnews']\n",
    "df_test = load_data(TEST_PATH, TEST_GS_PATH, all_test_files)\n",
    "\n",
    "print('\\n Train and test datasets loaded successfully')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extract Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adding POS based features...\n",
      "Adding synset-based features...\n",
      "Processed 2233 of 2234 rows (100%)      \n",
      "Adding lemma based features...\n",
      "Adding POS based features...\n",
      "Adding synset-based features...\n",
      "Processed 3107 of 3108 rows (100%)      \n",
      "Adding lemma based features...\n",
      "\n",
      " Features added to datasets successfully\n",
      "\n",
      " Train and test datasets saved as .csv files successfully\n"
     ]
    }
   ],
   "source": [
    "feature_extractor = FeatureExtractor()\n",
    "\n",
    "# Extract the desired features\n",
    "def add_features(dt):\n",
    "    feature_extractor.add_POS_statistics(dt)\n",
    "    feature_extractor.add_synset_statistics(dt)\n",
    "    feature_extractor.add_lemma_statistics(dt)\n",
    "\n",
    "# Add features to the training and test data\n",
    "add_features(df_train)\n",
    "add_features(df_test)\n",
    "\n",
    "print('\\n Features added to datasets successfully')\n",
    "\n",
    "# Save df_train and df_test to respective files - this is done to avoid re-running the\n",
    "# feature extraction process each time as synset extraction is computationally expensive\n",
    "df_test.to_csv(TEST_SAVE_PATH, index=False)\n",
    "df_train.to_csv(TRAIN_SAVE_PATH, index=False)\n",
    "\n",
    "print('\\n Train and test datasets saved as .csv files successfully')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pearson Score Calculations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Existing Dataframes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Train and test datasets loaded from .csv files successfully\n"
     ]
    }
   ],
   "source": [
    "if TRAIN_SAVE_PATH is None or TEST_SAVE_PATH is None:\n",
    "    raise ValueError('TRAIN_SAVE_PATH and TEST_SAVE_PATH must be defined')\n",
    "\n",
    "if not os.path.exists(TRAIN_SAVE_PATH):\n",
    "    raise FileNotFoundError(f'The file {TRAIN_SAVE_PATH} does not exist')\n",
    "\n",
    "if not os.path.exists(TEST_SAVE_PATH):\n",
    "    raise FileNotFoundError(f'The file {TEST_SAVE_PATH} does not exist')\n",
    "\n",
    "original_df_train = pd.read_csv(TRAIN_SAVE_PATH)\n",
    "original_df_test = pd.read_csv(TEST_SAVE_PATH)\n",
    "\n",
    "print('\\n Train and test datasets loaded from .csv files successfully')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Perform Feature Selection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Correlation Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                           s1_n_words  s2_n_words  s1_n_verbs_tot  \\\n",
      "s1_n_words                   1.000000    0.918735        0.758300   \n",
      "s2_n_words                   0.918735    1.000000        0.673713   \n",
      "s1_n_verbs_tot               0.758300    0.673713        1.000000   \n",
      "s2_n_verbs_tot               0.590479    0.698453        0.740191   \n",
      "s1_n_verbs_pres              0.246101    0.191457        0.571911   \n",
      "...                               ...         ...             ...   \n",
      "lemma_lcs_length             0.814533    0.793255        0.545660   \n",
      "lemma_edit_distance          0.781976    0.809274        0.570023   \n",
      "proportion_s1_in_s2          0.202598    0.231090        0.077001   \n",
      "proportion_s2_in_s1          0.298470    0.213312        0.158630   \n",
      "lemma_position_similarity    0.153036    0.110382        0.118022   \n",
      "\n",
      "                           s2_n_verbs_tot  s1_n_verbs_pres  s2_n_verbs_pres  \\\n",
      "s1_n_words                       0.590479         0.246101         0.113169   \n",
      "s2_n_words                       0.698453         0.191457         0.203622   \n",
      "s1_n_verbs_tot                   0.740191         0.571911         0.352796   \n",
      "s2_n_verbs_tot                   1.000000         0.359068         0.585477   \n",
      "s1_n_verbs_pres                  0.359068         1.000000         0.583186   \n",
      "...                                   ...              ...              ...   \n",
      "lemma_lcs_length                 0.470067         0.036863        -0.021604   \n",
      "lemma_edit_distance              0.542890         0.157074         0.102533   \n",
      "proportion_s1_in_s2              0.086514        -0.158674        -0.147527   \n",
      "proportion_s2_in_s1              0.070091        -0.122421        -0.165168   \n",
      "lemma_position_similarity        0.040985         0.016534        -0.049000   \n",
      "\n",
      "                           s1_n_verbs_past  s2_n_verbs_past  s1_n_nouns  \\\n",
      "s1_n_words                        0.541747         0.366501    0.879111   \n",
      "s2_n_words                        0.477406         0.426594    0.812494   \n",
      "s1_n_verbs_tot                    0.616441         0.373132    0.520241   \n",
      "s2_n_verbs_tot                    0.473997         0.555110    0.405833   \n",
      "s1_n_verbs_pres                  -0.088747        -0.161231    0.066217   \n",
      "...                                    ...              ...         ...   \n",
      "lemma_lcs_length                  0.519421         0.441736    0.812901   \n",
      "lemma_edit_distance               0.443265         0.373852    0.741351   \n",
      "proportion_s1_in_s2               0.210567         0.230728    0.230298   \n",
      "proportion_s2_in_s1               0.269901         0.213446    0.330817   \n",
      "lemma_position_similarity         0.090492         0.038153    0.128458   \n",
      "\n",
      "                           s2_n_nouns  ...  max_lemma_similarity  \\\n",
      "s1_n_words                   0.822095  ...              0.229858   \n",
      "s2_n_words                   0.884512  ...              0.150631   \n",
      "s1_n_verbs_tot               0.481373  ...              0.147050   \n",
      "s2_n_verbs_tot               0.451101  ...              0.017157   \n",
      "s1_n_verbs_pres              0.045344  ...             -0.036966   \n",
      "...                               ...  ...                   ...   \n",
      "lemma_lcs_length             0.808128  ...              0.301991   \n",
      "lemma_edit_distance          0.758161  ...              0.067852   \n",
      "proportion_s1_in_s2          0.283861  ...              0.543419   \n",
      "proportion_s2_in_s1          0.239628  ...              0.546156   \n",
      "lemma_position_similarity    0.109522  ...              0.828971   \n",
      "\n",
      "                           lemma_jackard_similarity  shared_lemma_count  \\\n",
      "s1_n_words                                 0.224797            0.823098   \n",
      "s2_n_words                                 0.204095            0.802170   \n",
      "s1_n_verbs_tot                             0.093844            0.546626   \n",
      "s2_n_verbs_tot                             0.066700            0.463084   \n",
      "s1_n_verbs_pres                           -0.138852            0.036443   \n",
      "...                                             ...                 ...   \n",
      "lemma_lcs_length                           0.552054            0.965594   \n",
      "lemma_edit_distance                       -0.085678            0.576657   \n",
      "proportion_s1_in_s2                        0.941852            0.575162   \n",
      "proportion_s2_in_s1                        0.936890            0.599770   \n",
      "lemma_position_similarity                  0.394989            0.214088   \n",
      "\n",
      "                           dice_coefficient  lemma_bigram_overlap  \\\n",
      "s1_n_words                         0.264632              0.169512   \n",
      "s2_n_words                         0.236947              0.153650   \n",
      "s1_n_verbs_tot                     0.125389              0.060910   \n",
      "s2_n_verbs_tot                     0.085188              0.051548   \n",
      "s1_n_verbs_pres                   -0.144292             -0.128608   \n",
      "...                                     ...                   ...   \n",
      "lemma_lcs_length                   0.582465              0.479089   \n",
      "lemma_edit_distance               -0.042950             -0.110112   \n",
      "proportion_s1_in_s2                0.962305              0.731835   \n",
      "proportion_s2_in_s1                0.959543              0.738100   \n",
      "lemma_position_similarity          0.499750              0.201317   \n",
      "\n",
      "                           lemma_lcs_length  lemma_edit_distance  \\\n",
      "s1_n_words                         0.814533             0.781976   \n",
      "s2_n_words                         0.793255             0.809274   \n",
      "s1_n_verbs_tot                     0.545660             0.570023   \n",
      "s2_n_verbs_tot                     0.470067             0.542890   \n",
      "s1_n_verbs_pres                    0.036863             0.157074   \n",
      "...                                     ...                  ...   \n",
      "lemma_lcs_length                   1.000000             0.508607   \n",
      "lemma_edit_distance                0.508607             1.000000   \n",
      "proportion_s1_in_s2                0.542896            -0.061796   \n",
      "proportion_s2_in_s1                0.568452            -0.020979   \n",
      "lemma_position_similarity          0.263695            -0.094165   \n",
      "\n",
      "                           proportion_s1_in_s2  proportion_s2_in_s1  \\\n",
      "s1_n_words                            0.202598             0.298470   \n",
      "s2_n_words                            0.231090             0.213312   \n",
      "s1_n_verbs_tot                        0.077001             0.158630   \n",
      "s2_n_verbs_tot                        0.086514             0.070091   \n",
      "s1_n_verbs_pres                      -0.158674            -0.122421   \n",
      "...                                        ...                  ...   \n",
      "lemma_lcs_length                      0.542896             0.568452   \n",
      "lemma_edit_distance                  -0.061796            -0.020979   \n",
      "proportion_s1_in_s2                   1.000000             0.852209   \n",
      "proportion_s2_in_s1                   0.852209             1.000000   \n",
      "lemma_position_similarity             0.484480             0.473087   \n",
      "\n",
      "                           lemma_position_similarity  \n",
      "s1_n_words                                  0.153036  \n",
      "s2_n_words                                  0.110382  \n",
      "s1_n_verbs_tot                              0.118022  \n",
      "s2_n_verbs_tot                              0.040985  \n",
      "s1_n_verbs_pres                             0.016534  \n",
      "...                                              ...  \n",
      "lemma_lcs_length                            0.263695  \n",
      "lemma_edit_distance                        -0.094165  \n",
      "proportion_s1_in_s2                         0.484480  \n",
      "proportion_s2_in_s1                         0.473087  \n",
      "lemma_position_similarity                   1.000000  \n",
      "\n",
      "[79 rows x 79 columns]\n",
      "\n",
      " Total number of columns (features) in the correlation matrix: 79\n"
     ]
    }
   ],
   "source": [
    "# Drop first 4 columns to remove non-numerical columns\n",
    "df_train = original_df_train.drop(original_df_train.columns[:4], axis=1)\n",
    "df_test = original_df_test.drop(original_df_test.columns[:4], axis=1)\n",
    "\n",
    "correlation_matrix = df_train.corr()\n",
    "print(correlation_matrix)\n",
    "\n",
    "# Total number of columns in the correlation matrix\n",
    "total_cols = correlation_matrix.shape[1]\n",
    "print(f'\\n Total number of columns (features) in the correlation matrix: {total_cols}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Drop Highly Correlated Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Number of features dropped: 32\n",
      "Remaining features after dropping highly correlated ones: Index(['s1_n_words', 's1_n_verbs_tot', 's2_n_verbs_tot', 's1_n_verbs_pres',\n",
      "       's2_n_verbs_pres', 's1_n_verbs_past', 's2_n_verbs_past',\n",
      "       's1_n_adjectives', 's1_n_adverbs', 's2_n_adverbs', 'dif_n_words',\n",
      "       'dif_n_verbs_tot', 'dif_n_verbs_pres', 'dif_n_verbs_past',\n",
      "       'dif_n_nouns', 'dif_n_adjectives', 'dif_n_adverbs', 'jaccard_all_words',\n",
      "       'jaccard_verbs', 'jaccard_nouns', 'jaccard_adjectives',\n",
      "       'jaccard_adverbs', 'all_all_shared_synsets_count',\n",
      "       'all_all_avg_synset_similarity', 'all_verb_shared_synsets_ratio',\n",
      "       'all_verb_avg_synset_similarity', 'all_verb_max_synset_similarity',\n",
      "       'all_noun_shared_synsets_ratio', 'all_noun_avg_synset_similarity',\n",
      "       'all_adj_shared_synsets_count', 'all_adj_shared_synsets_ratio',\n",
      "       'all_adj_max_synset_similarity', 'all_adv_shared_synsets_count',\n",
      "       'all_adv_shared_synsets_ratio', 'all_adv_max_synset_similarity',\n",
      "       'best_all_avg_synset_similarity', 'best_verb_shared_synsets_count',\n",
      "       'best_verb_max_synset_similarity', 'best_adj_shared_synsets_count',\n",
      "       'best_adj_avg_synset_similarity', 'best_adv_shared_synsets_count',\n",
      "       'best_adv_max_synset_similarity', 'avg_lemma_similarity',\n",
      "       'lemma_bigram_overlap', 'lemma_edit_distance', 'proportion_s2_in_s1',\n",
      "       'lemma_position_similarity'],\n",
      "      dtype='object')\n",
      "\n",
      "Number of remaining features after dropping highly correlated ones: 47\n",
      "\n",
      "Percentage of features removed: 40.51%\n",
      "\n",
      "Shape of df_test after column removal: (3108, 47)\n"
     ]
    }
   ],
   "source": [
    "# Initial number of columns\n",
    "total_cols = len(df_train.columns)\n",
    "\n",
    "# Find columns to drop from df_train and df_test\n",
    "dropped_columns = drop_highly_correlated_features(df_train)\n",
    "\n",
    "df_train_trimmed = df_train.drop(columns=dropped_columns)\n",
    "df_test_trimmed = df_test.drop(columns=dropped_columns)\n",
    "\n",
    "# Statistics\n",
    "print(f'\\nNumber of features dropped: {len(dropped_columns)}')\n",
    "print(\"Remaining features after dropping highly correlated ones:\", df_train_trimmed.columns)\n",
    "print(f'\\nNumber of remaining features after dropping highly correlated ones: {len(df_train_trimmed.columns)}')\n",
    "print(f'\\nPercentage of features removed: {(total_cols - len(df_train_trimmed.columns)) / total_cols * 100:.2f}%')\n",
    "\n",
    "# Print shape of df_test to verify consistency\n",
    "print(f'\\nShape of df_test after column removal: {df_test_trimmed.shape}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Pull remaining feature column names from df into \"all_features\"\n",
    "all_features = list(df_test_trimmed.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add the first 4 columns from df_train to df at the beginning\n",
    "df_train_trimmed = pd.concat([original_df_train[original_df_train.columns[:4]], df_train_trimmed], axis=1)\n",
    "df_test_trimmed = pd.concat([original_df_test[original_df_test.columns[:4]], df_test_trimmed], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define Used Feature Sets "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature sets for the analysis\n",
    "all_features = [\n",
    "            's1_n_words', 's1_n_verbs_tot', 's1_n_verbs_pres', 's1_n_verbs_past', 's1_n_nouns', 's1_n_adjectives', 's1_n_adverbs', \n",
    "            's2_n_words', 's2_n_verbs_tot', 's2_n_verbs_pres', 's2_n_verbs_past', 's2_n_nouns', 's2_n_adjectives', 's2_n_adverbs', \n",
    "            'dif_n_words', 'dif_n_verbs_tot', 'dif_n_verbs_pres', 'dif_n_verbs_past', 'dif_n_nouns', 'dif_n_adjectives', 'dif_n_adverbs', \n",
    "            'jaccard_all_words', 'jaccard_verbs', 'jaccard_nouns', 'jaccard_adjectives', 'jaccard_adverbs',\n",
    "            \n",
    "            'all_all_shared_synsets_count', 'all_all_shared_synsets_ratio', 'all_all_avg_synset_similarity', 'all_all_max_synset_similarity',\n",
    "            'all_verb_shared_synsets_count', 'all_verb_shared_synsets_ratio', 'all_verb_avg_synset_similarity', 'all_verb_max_synset_similarity',\n",
    "            'all_noun_shared_synsets_count', 'all_noun_shared_synsets_ratio', 'all_noun_avg_synset_similarity', 'all_noun_max_synset_similarity',\n",
    "            'all_adj_shared_synsets_count', 'all_adj_shared_synsets_ratio', 'all_adj_avg_synset_similarity', 'all_adj_max_synset_similarity',\n",
    "            'all_adv_shared_synsets_count', 'all_adv_shared_synsets_ratio', 'all_adv_avg_synset_similarity', 'all_adv_max_synset_similarity',\n",
    "\n",
    "            'best_all_shared_synsets_count', 'best_all_shared_synsets_ratio', 'best_all_avg_synset_similarity', 'best_all_max_synset_similarity',\n",
    "            'best_verb_shared_synsets_count', 'best_verb_shared_synsets_ratio', 'best_verb_avg_synset_similarity', 'best_verb_max_synset_similarity',\n",
    "            'best_noun_shared_synsets_count', 'best_noun_shared_synsets_ratio', 'best_noun_avg_synset_similarity', 'best_noun_max_synset_similarity',\n",
    "            'best_adj_shared_synsets_count', 'best_adj_shared_synsets_ratio', 'best_adj_avg_synset_similarity', 'best_adj_max_synset_similarity',\n",
    "            'best_adv_shared_synsets_count', 'best_adv_shared_synsets_ratio', 'best_adv_avg_synset_similarity', 'best_adv_max_synset_similarity',\n",
    "\n",
    "            'lemma_diversity', 'shared_lemmas_ratio', 'lemma_jackard_similarity', 'avg_lemma_similarity', 'max_lemma_similarity', 'shared_lemma_count', 'dice_coefficient',\n",
    "            'lemma_bigram_overlap', 'lemma_lcs_length', 'lemma_edit_distance', 'proportion_s1_in_s2', 'proportion_s2_in_s1', 'lemma_position_similarity'\n",
    "            ]\n",
    "\n",
    "PoS_features = [\n",
    "            's1_n_words', 's1_n_verbs_tot', 's1_n_verbs_pres', 's1_n_verbs_past', 's1_n_nouns', 's1_n_adjectives', 's1_n_adverbs', \n",
    "            's2_n_words', 's2_n_verbs_tot', 's2_n_verbs_pres', 's2_n_verbs_past', 's2_n_nouns', 's2_n_adjectives', 's2_n_adverbs', \n",
    "            'dif_n_words', 'dif_n_verbs_tot', 'dif_n_verbs_pres', 'dif_n_verbs_past', 'dif_n_nouns', 'dif_n_adjectives', 'dif_n_adverbs', \n",
    "            'jaccard_all_words', 'jaccard_verbs', 'jaccard_nouns', 'jaccard_adjectives', 'jaccard_adverbs',\n",
    "            ]\n",
    "\n",
    "synset_features = [\n",
    "            'all_all_shared_synsets_count', 'all_all_shared_synsets_ratio', 'all_all_avg_synset_similarity', 'all_all_max_synset_similarity',\n",
    "            'all_verb_shared_synsets_count', 'all_verb_shared_synsets_ratio', 'all_verb_avg_synset_similarity', 'all_verb_max_synset_similarity',\n",
    "            'all_noun_shared_synsets_count', 'all_noun_shared_synsets_ratio', 'all_noun_avg_synset_similarity', 'all_noun_max_synset_similarity',\n",
    "            'all_adj_shared_synsets_count', 'all_adj_shared_synsets_ratio', 'all_adj_avg_synset_similarity', 'all_adj_max_synset_similarity',\n",
    "            'all_adv_shared_synsets_count', 'all_adv_shared_synsets_ratio', 'all_adv_avg_synset_similarity', 'all_adv_max_synset_similarity',\n",
    "\n",
    "            'best_all_shared_synsets_count', 'best_all_shared_synsets_ratio', 'best_all_avg_synset_similarity', 'best_all_max_synset_similarity',\n",
    "            'best_verb_shared_synsets_count', 'best_verb_shared_synsets_ratio', 'best_verb_avg_synset_similarity', 'best_verb_max_synset_similarity',\n",
    "            'best_noun_shared_synsets_count', 'best_noun_shared_synsets_ratio', 'best_noun_avg_synset_similarity', 'best_noun_max_synset_similarity',\n",
    "            'best_adj_shared_synsets_count', 'best_adj_shared_synsets_ratio', 'best_adj_avg_synset_similarity', 'best_adj_max_synset_similarity',\n",
    "            'best_adv_shared_synsets_count', 'best_adv_shared_synsets_ratio', 'best_adv_avg_synset_similarity', 'best_adv_max_synset_similarity',\n",
    "            ]\n",
    "\n",
    "lemma_features = [\n",
    "            'lemma_diversity', 'shared_lemmas_ratio', 'lemma_jackard_similarity', 'avg_lemma_similarity', 'max_lemma_similarity', 'shared_lemma_count', 'dice_coefficient',\n",
    "            'lemma_bigram_overlap', 'lemma_lcs_length', 'lemma_edit_distance', 'proportion_s1_in_s2', 'proportion_s2_in_s1', 'lemma_position_similarity'\n",
    "            ]\n",
    "\n",
    "lexical_features = [\n",
    "            'all_all_shared_synsets_count', 'all_all_shared_synsets_ratio', 'all_all_avg_synset_similarity', 'all_all_max_synset_similarity',\n",
    "            'all_verb_shared_synsets_count', 'all_verb_shared_synsets_ratio', 'all_verb_avg_synset_similarity', 'all_verb_max_synset_similarity',\n",
    "            'all_noun_shared_synsets_count', 'all_noun_shared_synsets_ratio', 'all_noun_avg_synset_similarity', 'all_noun_max_synset_similarity',\n",
    "            'all_adj_shared_synsets_count', 'all_adj_shared_synsets_ratio', 'all_adj_avg_synset_similarity', 'all_adj_max_synset_similarity',\n",
    "            'all_adv_shared_synsets_count', 'all_adv_shared_synsets_ratio', 'all_adv_avg_synset_similarity', 'all_adv_max_synset_similarity',\n",
    "\n",
    "            'best_all_shared_synsets_count', 'best_all_shared_synsets_ratio', 'best_all_avg_synset_similarity', 'best_all_max_synset_similarity',\n",
    "            'best_verb_shared_synsets_count', 'best_verb_shared_synsets_ratio', 'best_verb_avg_synset_similarity', 'best_verb_max_synset_similarity',\n",
    "            'best_noun_shared_synsets_count', 'best_noun_shared_synsets_ratio', 'best_noun_avg_synset_similarity', 'best_noun_max_synset_similarity',\n",
    "            'best_adj_shared_synsets_count', 'best_adj_shared_synsets_ratio', 'best_adj_avg_synset_similarity', 'best_adj_max_synset_similarity',\n",
    "            'best_adv_shared_synsets_count', 'best_adv_shared_synsets_ratio', 'best_adv_avg_synset_similarity', 'best_adv_max_synset_similarity',\n",
    "\n",
    "            'lemma_diversity', 'shared_lemmas_ratio', 'lemma_jackard_similarity', 'avg_lemma_similarity', 'max_lemma_similarity', 'shared_lemma_count', 'dice_coefficient',\n",
    "            'lemma_bigram_overlap', 'lemma_lcs_length', 'lemma_edit_distance', 'proportion_s1_in_s2', 'proportion_s2_in_s1', 'lemma_position_similarity'\n",
    "]\n",
    "\n",
    "# Organize feature sets into labeled tuples\n",
    "features_sets = [\n",
    "    ('All', all_features),\n",
    "    ('Synsets', synset_features),\n",
    "    ('Lemmas', lemma_features),\n",
    "    ('PoS (Syntactic)', PoS_features),\n",
    "    ('Lexical', lexical_features),\n",
    "]\n",
    "\n",
    "# File sets for the analysis\n",
    "files_sets = [\n",
    "    ('SMTeuroparl', ['SMTeuroparl'], ['SMTeuroparl', 'surprise.OnWN', 'surprise.SMTnews']),\n",
    "    ('MSRvid', ['MSRvid'], ['MSRvid', 'surprise.OnWN', 'surprise.SMTnews']),\n",
    "    ('MSRpar', ['MSRpar'], ['MSRpar', 'surprise.OnWN', 'surprise.SMTnews']),\n",
    "    ('All', ['SMTeuroparl', 'MSRvid', 'MSRpar'], ['SMTeuroparl', 'MSRvid', 'MSRpar', 'surprise.OnWN', 'surprise.SMTnews'])\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Initialise Model Trainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_trainer = ModelTrainer()\n",
    "N_ITERATIONS = 10"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exploring Lexical Dimensions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Calculate Pearson Correlation Score using RF Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 96 candidates, totalling 480 fits\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[9], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m best_rf_model_lex, rf_params_lex, correlation_rf_lex, mean_correlation_rf_lex \u001b[38;5;241m=\u001b[39m \u001b[43mevaluate_rf_model\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m      2\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmodel_trainer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[0;32m      3\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdf_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[0;32m      4\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdf_test\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[0;32m      5\u001b[0m \u001b[43m    \u001b[49m\u001b[43mlexical_features\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[0;32m      6\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mgs\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[0;32m      7\u001b[0m \u001b[43m    \u001b[49m\u001b[43mPREDICTED_SAVE_PATH\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m      8\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mpredicted_rf_lex\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\n\u001b[0;32m      9\u001b[0m \u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\Kacpe\\Desktop\\College Work\\Repos\\Intro to HLT\\Work\\Labs\\project\\src\\utils.py:62\u001b[0m, in \u001b[0;36mevaluate_rf_model\u001b[1;34m(model_trainer, df_train, df_test, features, target_column, save_path, n_iterations)\u001b[0m\n\u001b[0;32m     58\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m     59\u001b[0m \u001b[38;5;124;03mEvaluate a Random Forest model using Pearson correlation.\u001b[39;00m\n\u001b[0;32m     60\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m     61\u001b[0m \u001b[38;5;66;03m# Find the best parameter combination and train the model\u001b[39;00m\n\u001b[1;32m---> 62\u001b[0m best_model, best_params \u001b[38;5;241m=\u001b[39m \u001b[43mmodel_trainer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain_RF\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdf_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfeatures\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtarget_column\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     64\u001b[0m \u001b[38;5;66;03m# Predict on test data and calculate single iteration correlation\u001b[39;00m\n\u001b[0;32m     65\u001b[0m df_test[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mpredicted\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m best_model\u001b[38;5;241m.\u001b[39mpredict(df_test[features])\n",
      "File \u001b[1;32mc:\\Users\\Kacpe\\Desktop\\College Work\\Repos\\Intro to HLT\\Work\\Labs\\project\\src\\models.py:170\u001b[0m, in \u001b[0;36mModelTrainer.train_RF\u001b[1;34m(self, df, input, output)\u001b[0m\n\u001b[0;32m    159\u001b[0m pearson_score \u001b[38;5;241m=\u001b[39m make_scorer(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpearson_scorer, greater_is_better\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m    161\u001b[0m grid_search \u001b[38;5;241m=\u001b[39m GridSearchCV(\n\u001b[0;32m    162\u001b[0m     estimator\u001b[38;5;241m=\u001b[39mmodel,\n\u001b[0;32m    163\u001b[0m     param_grid\u001b[38;5;241m=\u001b[39mparam_grid,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    167\u001b[0m     n_jobs\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m                          \n\u001b[0;32m    168\u001b[0m )\n\u001b[1;32m--> 170\u001b[0m \u001b[43mgrid_search\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    172\u001b[0m best_model \u001b[38;5;241m=\u001b[39m grid_search\u001b[38;5;241m.\u001b[39mbest_estimator_\n\u001b[0;32m    173\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mBest Hyperparameters:\u001b[39m\u001b[38;5;124m\"\u001b[39m, grid_search\u001b[38;5;241m.\u001b[39mbest_params_)\n",
      "File \u001b[1;32mc:\\Users\\Kacpe\\Desktop\\College Work\\Repos\\Intro to HLT\\Work\\Labs\\project\\venv\\Lib\\site-packages\\sklearn\\base.py:1473\u001b[0m, in \u001b[0;36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[1;34m(estimator, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1466\u001b[0m     estimator\u001b[38;5;241m.\u001b[39m_validate_params()\n\u001b[0;32m   1468\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[0;32m   1469\u001b[0m     skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[0;32m   1470\u001b[0m         prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[0;32m   1471\u001b[0m     )\n\u001b[0;32m   1472\u001b[0m ):\n\u001b[1;32m-> 1473\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfit_method\u001b[49m\u001b[43m(\u001b[49m\u001b[43mestimator\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\Kacpe\\Desktop\\College Work\\Repos\\Intro to HLT\\Work\\Labs\\project\\venv\\Lib\\site-packages\\sklearn\\model_selection\\_search.py:1019\u001b[0m, in \u001b[0;36mBaseSearchCV.fit\u001b[1;34m(self, X, y, **params)\u001b[0m\n\u001b[0;32m   1013\u001b[0m     results \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_format_results(\n\u001b[0;32m   1014\u001b[0m         all_candidate_params, n_splits, all_out, all_more_results\n\u001b[0;32m   1015\u001b[0m     )\n\u001b[0;32m   1017\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m results\n\u001b[1;32m-> 1019\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_run_search\u001b[49m\u001b[43m(\u001b[49m\u001b[43mevaluate_candidates\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1021\u001b[0m \u001b[38;5;66;03m# multimetric is determined here because in the case of a callable\u001b[39;00m\n\u001b[0;32m   1022\u001b[0m \u001b[38;5;66;03m# self.scoring the return type is only known after calling\u001b[39;00m\n\u001b[0;32m   1023\u001b[0m first_test_score \u001b[38;5;241m=\u001b[39m all_out[\u001b[38;5;241m0\u001b[39m][\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtest_scores\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n",
      "File \u001b[1;32mc:\\Users\\Kacpe\\Desktop\\College Work\\Repos\\Intro to HLT\\Work\\Labs\\project\\venv\\Lib\\site-packages\\sklearn\\model_selection\\_search.py:1573\u001b[0m, in \u001b[0;36mGridSearchCV._run_search\u001b[1;34m(self, evaluate_candidates)\u001b[0m\n\u001b[0;32m   1571\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_run_search\u001b[39m(\u001b[38;5;28mself\u001b[39m, evaluate_candidates):\n\u001b[0;32m   1572\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Search all candidates in param_grid\"\"\"\u001b[39;00m\n\u001b[1;32m-> 1573\u001b[0m     \u001b[43mevaluate_candidates\u001b[49m\u001b[43m(\u001b[49m\u001b[43mParameterGrid\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mparam_grid\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\Kacpe\\Desktop\\College Work\\Repos\\Intro to HLT\\Work\\Labs\\project\\venv\\Lib\\site-packages\\sklearn\\model_selection\\_search.py:965\u001b[0m, in \u001b[0;36mBaseSearchCV.fit.<locals>.evaluate_candidates\u001b[1;34m(candidate_params, cv, more_results)\u001b[0m\n\u001b[0;32m    957\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mverbose \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[0;32m    958\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\n\u001b[0;32m    959\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFitting \u001b[39m\u001b[38;5;132;01m{0}\u001b[39;00m\u001b[38;5;124m folds for each of \u001b[39m\u001b[38;5;132;01m{1}\u001b[39;00m\u001b[38;5;124m candidates,\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    960\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m totalling \u001b[39m\u001b[38;5;132;01m{2}\u001b[39;00m\u001b[38;5;124m fits\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(\n\u001b[0;32m    961\u001b[0m             n_splits, n_candidates, n_candidates \u001b[38;5;241m*\u001b[39m n_splits\n\u001b[0;32m    962\u001b[0m         )\n\u001b[0;32m    963\u001b[0m     )\n\u001b[1;32m--> 965\u001b[0m out \u001b[38;5;241m=\u001b[39m \u001b[43mparallel\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    966\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdelayed\u001b[49m\u001b[43m(\u001b[49m\u001b[43m_fit_and_score\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    967\u001b[0m \u001b[43m        \u001b[49m\u001b[43mclone\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbase_estimator\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    968\u001b[0m \u001b[43m        \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    969\u001b[0m \u001b[43m        \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    970\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtrain\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtrain\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    971\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtest\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtest\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    972\u001b[0m \u001b[43m        \u001b[49m\u001b[43mparameters\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mparameters\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    973\u001b[0m \u001b[43m        \u001b[49m\u001b[43msplit_progress\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43msplit_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_splits\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    974\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcandidate_progress\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mcand_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_candidates\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    975\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mfit_and_score_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    976\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    977\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mcand_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mparameters\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43msplit_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtest\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mproduct\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    978\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43menumerate\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mcandidate_params\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    979\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43menumerate\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mcv\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msplit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mrouted_params\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msplitter\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msplit\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    980\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    981\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    983\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(out) \u001b[38;5;241m<\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[0;32m    984\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    985\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNo fits were performed. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    986\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mWas the CV iterator empty? \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    987\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mWere there no candidates?\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    988\u001b[0m     )\n",
      "File \u001b[1;32mc:\\Users\\Kacpe\\Desktop\\College Work\\Repos\\Intro to HLT\\Work\\Labs\\project\\venv\\Lib\\site-packages\\sklearn\\utils\\parallel.py:74\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m     69\u001b[0m config \u001b[38;5;241m=\u001b[39m get_config()\n\u001b[0;32m     70\u001b[0m iterable_with_config \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m     71\u001b[0m     (_with_config(delayed_func, config), args, kwargs)\n\u001b[0;32m     72\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m delayed_func, args, kwargs \u001b[38;5;129;01min\u001b[39;00m iterable\n\u001b[0;32m     73\u001b[0m )\n\u001b[1;32m---> 74\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__call__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43miterable_with_config\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\Kacpe\\Desktop\\College Work\\Repos\\Intro to HLT\\Work\\Labs\\project\\venv\\Lib\\site-packages\\joblib\\parallel.py:2007\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m   2001\u001b[0m \u001b[38;5;66;03m# The first item from the output is blank, but it makes the interpreter\u001b[39;00m\n\u001b[0;32m   2002\u001b[0m \u001b[38;5;66;03m# progress until it enters the Try/Except block of the generator and\u001b[39;00m\n\u001b[0;32m   2003\u001b[0m \u001b[38;5;66;03m# reaches the first `yield` statement. This starts the asynchronous\u001b[39;00m\n\u001b[0;32m   2004\u001b[0m \u001b[38;5;66;03m# dispatch of the tasks to the workers.\u001b[39;00m\n\u001b[0;32m   2005\u001b[0m \u001b[38;5;28mnext\u001b[39m(output)\n\u001b[1;32m-> 2007\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m output \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mreturn_generator \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43moutput\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\Kacpe\\Desktop\\College Work\\Repos\\Intro to HLT\\Work\\Labs\\project\\venv\\Lib\\site-packages\\joblib\\parallel.py:1650\u001b[0m, in \u001b[0;36mParallel._get_outputs\u001b[1;34m(self, iterator, pre_dispatch)\u001b[0m\n\u001b[0;32m   1647\u001b[0m     \u001b[38;5;28;01myield\u001b[39;00m\n\u001b[0;32m   1649\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backend\u001b[38;5;241m.\u001b[39mretrieval_context():\n\u001b[1;32m-> 1650\u001b[0m         \u001b[38;5;28;01myield from\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_retrieve()\n\u001b[0;32m   1652\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mGeneratorExit\u001b[39;00m:\n\u001b[0;32m   1653\u001b[0m     \u001b[38;5;66;03m# The generator has been garbage collected before being fully\u001b[39;00m\n\u001b[0;32m   1654\u001b[0m     \u001b[38;5;66;03m# consumed. This aborts the remaining tasks if possible and warn\u001b[39;00m\n\u001b[0;32m   1655\u001b[0m     \u001b[38;5;66;03m# the user if necessary.\u001b[39;00m\n\u001b[0;32m   1656\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_exception \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\Kacpe\\Desktop\\College Work\\Repos\\Intro to HLT\\Work\\Labs\\project\\venv\\Lib\\site-packages\\joblib\\parallel.py:1762\u001b[0m, in \u001b[0;36mParallel._retrieve\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1757\u001b[0m \u001b[38;5;66;03m# If the next job is not ready for retrieval yet, we just wait for\u001b[39;00m\n\u001b[0;32m   1758\u001b[0m \u001b[38;5;66;03m# async callbacks to progress.\u001b[39;00m\n\u001b[0;32m   1759\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m ((\u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jobs) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m) \u001b[38;5;129;01mor\u001b[39;00m\n\u001b[0;32m   1760\u001b[0m     (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jobs[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39mget_status(\n\u001b[0;32m   1761\u001b[0m         timeout\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtimeout) \u001b[38;5;241m==\u001b[39m TASK_PENDING)):\n\u001b[1;32m-> 1762\u001b[0m     \u001b[43mtime\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msleep\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m0.01\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1763\u001b[0m     \u001b[38;5;28;01mcontinue\u001b[39;00m\n\u001b[0;32m   1765\u001b[0m \u001b[38;5;66;03m# We need to be careful: the job list can be filling up as\u001b[39;00m\n\u001b[0;32m   1766\u001b[0m \u001b[38;5;66;03m# we empty it and Python list are not thread-safe by\u001b[39;00m\n\u001b[0;32m   1767\u001b[0m \u001b[38;5;66;03m# default hence the use of the lock\u001b[39;00m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "best_rf_model_lex, rf_params_lex, correlation_rf_lex, mean_correlation_rf_lex = evaluate_rf_model(\n",
    "    model_trainer, \n",
    "    df_train, \n",
    "    df_test, \n",
    "    lexical_features, \n",
    "    'gs', \n",
    "    PREDICTED_SAVE_PATH,\n",
    "    \"predicted_rf_lex\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exploring Syntactic Dimensions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Calculate Pearson Correlation Score using RF Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 96 candidates, totalling 480 fits\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[10], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m best_rf_model_pos, rf_params_pos, correlation_rf_pos, mean_correlation_rf_pos \u001b[38;5;241m=\u001b[39m \u001b[43mevaluate_rf_model\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m      2\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmodel_trainer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[0;32m      3\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdf_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[0;32m      4\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdf_test\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[0;32m      5\u001b[0m \u001b[43m    \u001b[49m\u001b[43mPoS_features\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[0;32m      6\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mgs\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[0;32m      7\u001b[0m \u001b[43m    \u001b[49m\u001b[43mPREDICTED_SAVE_PATH\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m      8\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mpredicted_rf_pos\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\n\u001b[0;32m      9\u001b[0m \u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\Kacpe\\Desktop\\College Work\\Repos\\Intro to HLT\\Work\\Labs\\project\\src\\utils.py:62\u001b[0m, in \u001b[0;36mevaluate_rf_model\u001b[1;34m(model_trainer, df_train, df_test, features, target_column, save_path, n_iterations)\u001b[0m\n\u001b[0;32m     58\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m     59\u001b[0m \u001b[38;5;124;03mEvaluate a Random Forest model using Pearson correlation.\u001b[39;00m\n\u001b[0;32m     60\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m     61\u001b[0m \u001b[38;5;66;03m# Find the best parameter combination and train the model\u001b[39;00m\n\u001b[1;32m---> 62\u001b[0m best_model, best_params \u001b[38;5;241m=\u001b[39m \u001b[43mmodel_trainer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain_RF\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdf_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfeatures\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtarget_column\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     64\u001b[0m \u001b[38;5;66;03m# Predict on test data and calculate single iteration correlation\u001b[39;00m\n\u001b[0;32m     65\u001b[0m df_test[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mpredicted\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m best_model\u001b[38;5;241m.\u001b[39mpredict(df_test[features])\n",
      "File \u001b[1;32mc:\\Users\\Kacpe\\Desktop\\College Work\\Repos\\Intro to HLT\\Work\\Labs\\project\\src\\models.py:170\u001b[0m, in \u001b[0;36mModelTrainer.train_RF\u001b[1;34m(self, df, input, output)\u001b[0m\n\u001b[0;32m    159\u001b[0m pearson_score \u001b[38;5;241m=\u001b[39m make_scorer(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpearson_scorer, greater_is_better\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m    161\u001b[0m grid_search \u001b[38;5;241m=\u001b[39m GridSearchCV(\n\u001b[0;32m    162\u001b[0m     estimator\u001b[38;5;241m=\u001b[39mmodel,\n\u001b[0;32m    163\u001b[0m     param_grid\u001b[38;5;241m=\u001b[39mparam_grid,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    167\u001b[0m     n_jobs\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m                          \n\u001b[0;32m    168\u001b[0m )\n\u001b[1;32m--> 170\u001b[0m \u001b[43mgrid_search\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    172\u001b[0m best_model \u001b[38;5;241m=\u001b[39m grid_search\u001b[38;5;241m.\u001b[39mbest_estimator_\n\u001b[0;32m    173\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mBest Hyperparameters:\u001b[39m\u001b[38;5;124m\"\u001b[39m, grid_search\u001b[38;5;241m.\u001b[39mbest_params_)\n",
      "File \u001b[1;32mc:\\Users\\Kacpe\\Desktop\\College Work\\Repos\\Intro to HLT\\Work\\Labs\\project\\venv\\Lib\\site-packages\\sklearn\\base.py:1473\u001b[0m, in \u001b[0;36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[1;34m(estimator, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1466\u001b[0m     estimator\u001b[38;5;241m.\u001b[39m_validate_params()\n\u001b[0;32m   1468\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[0;32m   1469\u001b[0m     skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[0;32m   1470\u001b[0m         prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[0;32m   1471\u001b[0m     )\n\u001b[0;32m   1472\u001b[0m ):\n\u001b[1;32m-> 1473\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfit_method\u001b[49m\u001b[43m(\u001b[49m\u001b[43mestimator\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\Kacpe\\Desktop\\College Work\\Repos\\Intro to HLT\\Work\\Labs\\project\\venv\\Lib\\site-packages\\sklearn\\model_selection\\_search.py:1019\u001b[0m, in \u001b[0;36mBaseSearchCV.fit\u001b[1;34m(self, X, y, **params)\u001b[0m\n\u001b[0;32m   1013\u001b[0m     results \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_format_results(\n\u001b[0;32m   1014\u001b[0m         all_candidate_params, n_splits, all_out, all_more_results\n\u001b[0;32m   1015\u001b[0m     )\n\u001b[0;32m   1017\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m results\n\u001b[1;32m-> 1019\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_run_search\u001b[49m\u001b[43m(\u001b[49m\u001b[43mevaluate_candidates\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1021\u001b[0m \u001b[38;5;66;03m# multimetric is determined here because in the case of a callable\u001b[39;00m\n\u001b[0;32m   1022\u001b[0m \u001b[38;5;66;03m# self.scoring the return type is only known after calling\u001b[39;00m\n\u001b[0;32m   1023\u001b[0m first_test_score \u001b[38;5;241m=\u001b[39m all_out[\u001b[38;5;241m0\u001b[39m][\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtest_scores\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n",
      "File \u001b[1;32mc:\\Users\\Kacpe\\Desktop\\College Work\\Repos\\Intro to HLT\\Work\\Labs\\project\\venv\\Lib\\site-packages\\sklearn\\model_selection\\_search.py:1573\u001b[0m, in \u001b[0;36mGridSearchCV._run_search\u001b[1;34m(self, evaluate_candidates)\u001b[0m\n\u001b[0;32m   1571\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_run_search\u001b[39m(\u001b[38;5;28mself\u001b[39m, evaluate_candidates):\n\u001b[0;32m   1572\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Search all candidates in param_grid\"\"\"\u001b[39;00m\n\u001b[1;32m-> 1573\u001b[0m     \u001b[43mevaluate_candidates\u001b[49m\u001b[43m(\u001b[49m\u001b[43mParameterGrid\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mparam_grid\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\Kacpe\\Desktop\\College Work\\Repos\\Intro to HLT\\Work\\Labs\\project\\venv\\Lib\\site-packages\\sklearn\\model_selection\\_search.py:965\u001b[0m, in \u001b[0;36mBaseSearchCV.fit.<locals>.evaluate_candidates\u001b[1;34m(candidate_params, cv, more_results)\u001b[0m\n\u001b[0;32m    957\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mverbose \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[0;32m    958\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\n\u001b[0;32m    959\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFitting \u001b[39m\u001b[38;5;132;01m{0}\u001b[39;00m\u001b[38;5;124m folds for each of \u001b[39m\u001b[38;5;132;01m{1}\u001b[39;00m\u001b[38;5;124m candidates,\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    960\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m totalling \u001b[39m\u001b[38;5;132;01m{2}\u001b[39;00m\u001b[38;5;124m fits\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(\n\u001b[0;32m    961\u001b[0m             n_splits, n_candidates, n_candidates \u001b[38;5;241m*\u001b[39m n_splits\n\u001b[0;32m    962\u001b[0m         )\n\u001b[0;32m    963\u001b[0m     )\n\u001b[1;32m--> 965\u001b[0m out \u001b[38;5;241m=\u001b[39m \u001b[43mparallel\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    966\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdelayed\u001b[49m\u001b[43m(\u001b[49m\u001b[43m_fit_and_score\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    967\u001b[0m \u001b[43m        \u001b[49m\u001b[43mclone\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbase_estimator\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    968\u001b[0m \u001b[43m        \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    969\u001b[0m \u001b[43m        \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    970\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtrain\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtrain\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    971\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtest\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtest\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    972\u001b[0m \u001b[43m        \u001b[49m\u001b[43mparameters\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mparameters\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    973\u001b[0m \u001b[43m        \u001b[49m\u001b[43msplit_progress\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43msplit_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_splits\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    974\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcandidate_progress\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mcand_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_candidates\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    975\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mfit_and_score_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    976\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    977\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mcand_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mparameters\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43msplit_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtest\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mproduct\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    978\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43menumerate\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mcandidate_params\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    979\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43menumerate\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mcv\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msplit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mrouted_params\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msplitter\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msplit\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    980\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    981\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    983\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(out) \u001b[38;5;241m<\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[0;32m    984\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    985\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNo fits were performed. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    986\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mWas the CV iterator empty? \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    987\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mWere there no candidates?\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    988\u001b[0m     )\n",
      "File \u001b[1;32mc:\\Users\\Kacpe\\Desktop\\College Work\\Repos\\Intro to HLT\\Work\\Labs\\project\\venv\\Lib\\site-packages\\sklearn\\utils\\parallel.py:74\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m     69\u001b[0m config \u001b[38;5;241m=\u001b[39m get_config()\n\u001b[0;32m     70\u001b[0m iterable_with_config \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m     71\u001b[0m     (_with_config(delayed_func, config), args, kwargs)\n\u001b[0;32m     72\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m delayed_func, args, kwargs \u001b[38;5;129;01min\u001b[39;00m iterable\n\u001b[0;32m     73\u001b[0m )\n\u001b[1;32m---> 74\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__call__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43miterable_with_config\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\Kacpe\\Desktop\\College Work\\Repos\\Intro to HLT\\Work\\Labs\\project\\venv\\Lib\\site-packages\\joblib\\parallel.py:2007\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m   2001\u001b[0m \u001b[38;5;66;03m# The first item from the output is blank, but it makes the interpreter\u001b[39;00m\n\u001b[0;32m   2002\u001b[0m \u001b[38;5;66;03m# progress until it enters the Try/Except block of the generator and\u001b[39;00m\n\u001b[0;32m   2003\u001b[0m \u001b[38;5;66;03m# reaches the first `yield` statement. This starts the asynchronous\u001b[39;00m\n\u001b[0;32m   2004\u001b[0m \u001b[38;5;66;03m# dispatch of the tasks to the workers.\u001b[39;00m\n\u001b[0;32m   2005\u001b[0m \u001b[38;5;28mnext\u001b[39m(output)\n\u001b[1;32m-> 2007\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m output \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mreturn_generator \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43moutput\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\Kacpe\\Desktop\\College Work\\Repos\\Intro to HLT\\Work\\Labs\\project\\venv\\Lib\\site-packages\\joblib\\parallel.py:1650\u001b[0m, in \u001b[0;36mParallel._get_outputs\u001b[1;34m(self, iterator, pre_dispatch)\u001b[0m\n\u001b[0;32m   1647\u001b[0m     \u001b[38;5;28;01myield\u001b[39;00m\n\u001b[0;32m   1649\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backend\u001b[38;5;241m.\u001b[39mretrieval_context():\n\u001b[1;32m-> 1650\u001b[0m         \u001b[38;5;28;01myield from\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_retrieve()\n\u001b[0;32m   1652\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mGeneratorExit\u001b[39;00m:\n\u001b[0;32m   1653\u001b[0m     \u001b[38;5;66;03m# The generator has been garbage collected before being fully\u001b[39;00m\n\u001b[0;32m   1654\u001b[0m     \u001b[38;5;66;03m# consumed. This aborts the remaining tasks if possible and warn\u001b[39;00m\n\u001b[0;32m   1655\u001b[0m     \u001b[38;5;66;03m# the user if necessary.\u001b[39;00m\n\u001b[0;32m   1656\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_exception \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\Kacpe\\Desktop\\College Work\\Repos\\Intro to HLT\\Work\\Labs\\project\\venv\\Lib\\site-packages\\joblib\\parallel.py:1762\u001b[0m, in \u001b[0;36mParallel._retrieve\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1757\u001b[0m \u001b[38;5;66;03m# If the next job is not ready for retrieval yet, we just wait for\u001b[39;00m\n\u001b[0;32m   1758\u001b[0m \u001b[38;5;66;03m# async callbacks to progress.\u001b[39;00m\n\u001b[0;32m   1759\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m ((\u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jobs) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m) \u001b[38;5;129;01mor\u001b[39;00m\n\u001b[0;32m   1760\u001b[0m     (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jobs[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39mget_status(\n\u001b[0;32m   1761\u001b[0m         timeout\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtimeout) \u001b[38;5;241m==\u001b[39m TASK_PENDING)):\n\u001b[1;32m-> 1762\u001b[0m     \u001b[43mtime\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msleep\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m0.01\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1763\u001b[0m     \u001b[38;5;28;01mcontinue\u001b[39;00m\n\u001b[0;32m   1765\u001b[0m \u001b[38;5;66;03m# We need to be careful: the job list can be filling up as\u001b[39;00m\n\u001b[0;32m   1766\u001b[0m \u001b[38;5;66;03m# we empty it and Python list are not thread-safe by\u001b[39;00m\n\u001b[0;32m   1767\u001b[0m \u001b[38;5;66;03m# default hence the use of the lock\u001b[39;00m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "best_rf_model_pos, rf_params_pos, correlation_rf_pos, mean_correlation_rf_pos = evaluate_rf_model(\n",
    "    model_trainer, \n",
    "    df_train, \n",
    "    df_test, \n",
    "    PoS_features, \n",
    "    'gs', \n",
    "    PREDICTED_SAVE_PATH,\n",
    "    \"predicted_rf_pos\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exploring Lexical + Syntactic Dimensions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Calculate Pearson Correlation Score using RF Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 96 candidates, totalling 480 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\projects\\MAI\\IHLT\\Intro-to-IHLT-Labs\\.venv\\Lib\\site-packages\\numpy\\ma\\core.py:2846: RuntimeWarning: invalid value encountered in cast\n",
      "  _data = np.array(data, dtype=dtype, copy=copy,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Hyperparameters: {'bootstrap': False, 'max_depth': None, 'max_features': 'sqrt', 'min_samples_leaf': 1, 'min_samples_split': 2, 'n_estimators': 300}\n",
      "\n",
      " Pearson correlation for the best RF model: 0.755781278357736\n",
      "Predicted data saved to CSV: ../data/test/03_predicted/2024-12-09_20-27-37_predicted_rf_predicted_test_data.csv\n",
      "Predicted data saved to Excel: ../data/test/03_predicted/2024-12-09_20-27-37_predicted_rf_predicted_test_data.xlsx\n",
      "Computing mean Pearson correlation for 10 iterations...\n",
      "Mean Pearson correlation: 0.7552431439444272\n"
     ]
    }
   ],
   "source": [
    "best_rf_model_lex_pos, rf_params_lex_pos, correlation_rf_lex_pos, mean_correlation_rf_lex_pos = evaluate_rf_model(\n",
    "    model_trainer, \n",
    "    df_train, \n",
    "    df_test, \n",
    "    lexical_features + PoS_features, \n",
    "    'gs', \n",
    "    PREDICTED_SAVE_PATH,\n",
    "    \"predicted_rf_lex_pos\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exploring Additional Dimensions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Calculate Pearson Correlation Score using RF Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 96 candidates, totalling 480 fits\n",
      "Best Hyperparameters: {'bootstrap': False, 'max_depth': None, 'max_features': 'sqrt', 'min_samples_leaf': 1, 'min_samples_split': 2, 'n_estimators': 300}\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Pearson correlation for the best RF model: 0.7610017636453011\n",
      "Computing mean Pearson correlation for 10 iterations...\n",
      "Mean Pearson correlation over 10 iterations: 0.7626539074321047\n",
      "Predicted data saved to CSV: ../data/test/03_predicted/2024-12-10_16-27-26_predicted_rf_all_predicted_test_data.csv\n",
      "Predicted data saved to Excel: ../data/test/03_predicted/2024-12-10_16-27-26_predicted_rf_all_predicted_test_data.xlsx\n"
     ]
    }
   ],
   "source": [
    "best_rf_model_all, rf_params_all, correlation_rf_all, mean_correlation_rf_all = evaluate_rf_model(\n",
    "    model_trainer, \n",
    "    df_train_trimmed, \n",
    "    df_test_trimmed, \n",
    "    all_features, \n",
    "    'gs', \n",
    "    PREDICTED_SAVE_PATH,\n",
    "    \"predicted_rf_all\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluation of Additional Models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### NN Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 8 candidates, totalling 24 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Kacpe\\Desktop\\College Work\\Repos\\Intro to HLT\\Work\\Labs\\project\\venv\\Lib\\site-packages\\keras\\src\\layers\\core\\dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Parameters: {'batch_size': 16, 'epochs': 100, 'model__hidden_layers': 2, 'model__learning_rate': 0.001, 'model__neurons': 10}\n",
      "\n",
      " Pearson correlation for the best NN model: 0.6998561595755382\n",
      "Predicted data saved to CSV: ../data/test/03_predicted/2024-12-10_11-18-48_predicted_nn_all.csv_predicted_test_data.csv\n",
      "Predicted data saved to Excel: ../data/test/03_predicted/2024-12-10_11-18-48_predicted_nn_all.csv_predicted_test_data.xlsx\n"
     ]
    }
   ],
   "source": [
    "# Train the best NN model using all features\n",
    "best_nn_model = model_trainer.train_NN(df_train, all_features, 'gs')\n",
    "\n",
    "# Predict the test data\n",
    "df_test['predicted_nn'] = best_nn_model.predict(df_test[all_features])\n",
    "\n",
    "# Calculate the Pearson correlation for the best NN model\n",
    "correlation_nn = pearsonr(df_test['gs'], df_test['predicted_nn'])[0]\n",
    "print(f'\\n Pearson correlation for the best NN model: {correlation_nn}')\n",
    "\n",
    "# Save the predictions\n",
    "save_predictions(df_test, PREDICTED_SAVE_PATH, 'predicted_nn_all.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### MLP Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 144 candidates, totalling 720 fits\n",
      "Best Hyperparameters: {'activation': 'relu', 'alpha': 0.01, 'hidden_layer_sizes': (100,), 'learning_rate': 'adaptive', 'max_iter': 500, 'solver': 'adam'}\n",
      "\n",
      " Pearson correlation for the best MLP model: 0.711672456928118\n",
      "Predicted data saved to CSV: ../data/test/03_predicted/2024-12-10_11-07-41_predicted_mlp_all.csv_predicted_test_data.csv\n",
      "Predicted data saved to Excel: ../data/test/03_predicted/2024-12-10_11-07-41_predicted_mlp_all.csv_predicted_test_data.xlsx\n"
     ]
    }
   ],
   "source": [
    "# Train the best MLP model using all features\n",
    "best_mlp_model = model_trainer.train_MLP(df_train, all_features, 'gs')\n",
    "\n",
    "# Predict the test data\n",
    "df_test['predicted_mlp'] = best_mlp_model.predict(df_test[all_features])\n",
    "\n",
    "# Calculate the Pearson correlation for the best NN model\n",
    "correlation_mlp = pearsonr(df_test['gs'], df_test['predicted_mlp'])[0]\n",
    "print(f'\\n Pearson correlation for the best MLP model: {correlation_mlp}')\n",
    "\n",
    "# Save the predictions\n",
    "save_predictions(df_test, PREDICTED_SAVE_PATH, 'predicted_mlp_all.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### SVR Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Kacpe\\Desktop\\College Work\\Repos\\Intro to HLT\\Work\\Labs\\project\\venv\\Lib\\site-packages\\sklearn\\model_selection\\_search.py:320: UserWarning: The total space of parameters 8 is smaller than n_iter=20. Running 8 iterations. For exhaustive searches, use GridSearchCV.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 8 candidates, totalling 24 fits\n",
      "Best params: {'kernel': 'rbf', 'gamma': 'scale', 'C': 1}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Kacpe\\Desktop\\College Work\\Repos\\Intro to HLT\\Work\\Labs\\project\\venv\\Lib\\site-packages\\sklearn\\base.py:486: UserWarning: X has feature names, but SVR was fitted without feature names\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Pearson correlation for the best SVR model: -0.16273316207516741\n",
      "Predicted data saved to CSV: ../data/test/03_predicted/2024-12-10_11-08-25_predicted_svr_all.csv_predicted_test_data.csv\n",
      "Predicted data saved to Excel: ../data/test/03_predicted/2024-12-10_11-08-25_predicted_svr_all.csv_predicted_test_data.xlsx\n"
     ]
    }
   ],
   "source": [
    "# Train the best SVR model using all features\n",
    "best_svr_model = model_trainer.train_SVR(df_train, all_features, 'gs')\n",
    "\n",
    "# Predict the test data\n",
    "df_test['predicted_svr'] = best_svr_model.predict(df_test[all_features])\n",
    "\n",
    "# Calculate the Pearson correlation for the best SVR model\n",
    "correlation_svr = pearsonr(df_test['gs'], df_test['predicted_svr'])[0]\n",
    "print(f'\\n Pearson correlation for the best SVR model: {correlation_svr}')\n",
    "\n",
    "# Save the predictions\n",
    "save_predictions(df_test, PREDICTED_SAVE_PATH, 'predicted_svr_all.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Additional Code (TODO: Discuss if we're keeping this)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compare correlation based on file and features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "All SMTeuroparl 0.5260762425283135\n",
      "All SMTeuroparl 0.6321408221170948 (with surprise files)\n",
      "Synsets SMTeuroparl 0.5089847580757192\n",
      "Synsets SMTeuroparl 0.5984333819281736 (with surprise files)\n",
      "Lemmas SMTeuroparl 0.48728005311908856\n",
      "Lemmas SMTeuroparl 0.5838403729608709 (with surprise files)\n",
      "PoS (Syntactical) SMTeuroparl 0.28082396513890506\n",
      "PoS (Syntactical) SMTeuroparl 0.3062866488678532 (with surprise files)\n",
      "Lexical SMTeuroparl 0.5317844394052379\n",
      "Lexical SMTeuroparl 0.6256457418945189 (with surprise files)\n",
      "\n",
      "All MSRvid 0.8611804247098516\n",
      "All MSRvid 0.7915275196347473 (with surprise files)\n",
      "Synsets MSRvid 0.8597524788987414\n",
      "Synsets MSRvid 0.7654246344934643 (with surprise files)\n",
      "Lemmas MSRvid 0.6572899927033499\n",
      "Lemmas MSRvid 0.6420521699471147 (with surprise files)\n",
      "PoS (Syntactical) MSRvid 0.20808034566065797\n",
      "PoS (Syntactical) MSRvid 0.35248343346031863 (with surprise files)\n",
      "Lexical MSRvid 0.8620913345693634\n",
      "Lexical MSRvid 0.7776658207000915 (with surprise files)\n",
      "\n",
      "All MSRpar 0.5980055133354054\n",
      "All MSRpar 0.5228975085251519 (with surprise files)\n",
      "Synsets MSRpar 0.5177578550169951\n",
      "Synsets MSRpar 0.4476150310809409 (with surprise files)\n",
      "Lemmas MSRpar 0.5530242136102264\n",
      "Lemmas MSRpar 0.5424651769788617 (with surprise files)\n",
      "PoS (Syntactical) MSRpar 0.3351401615843118\n",
      "PoS (Syntactical) MSRpar 0.020682043233786286 (with surprise files)\n",
      "Lexical MSRpar 0.5900589694756582\n",
      "Lexical MSRpar 0.5382029182207234 (with surprise files)\n",
      "\n",
      "All All 0.8032769795343603\n",
      "All All 0.7541890174149117 (with surprise files)\n",
      "Synsets All 0.7835546046102503\n",
      "Synsets All 0.7242258621409416 (with surprise files)\n",
      "Lemmas All 0.6935845573569963\n",
      "Lemmas All 0.6414015564547721 (with surprise files)\n",
      "PoS (Syntactical) All 0.4763025071936748\n",
      "PoS (Syntactical) All 0.4546740328382729 (with surprise files)\n",
      "Lexical All 0.8032998452799843\n",
      "Lexical All 0.7456461981167642 (with surprise files)\n"
     ]
    }
   ],
   "source": [
    "N_ITERS = 10\n",
    "# Train a Random Forest for each feature set and each file set\n",
    "for t_name, tr_set, vl_set in files_sets:\n",
    "    print()\n",
    "    for f_name, f_set in features_sets:\n",
    "        train = df_train[df_train['file'].isin(tr_set)]\n",
    "        \n",
    "        test = df_test[df_test['file'].isin(tr_set)]\n",
    "        corr = 0\n",
    "        for i in range(N_ITERS):\n",
    "            model = train_single_RF(train, f_set, 'gs', params)\n",
    "            test.loc[:, 'predicted'] = model.predict(test[f_set])\n",
    "            corr += pearsonr(test['gs'], test['predicted'])[0]\n",
    "        print(f_name, t_name, corr / N_ITERS)\n",
    "\n",
    "        test = df_test[df_test['file'].isin(vl_set)]\n",
    "        corr = 0\n",
    "        for i in range(N_ITERS):\n",
    "            model = train_single_RF(train, f_set, 'gs', params)\n",
    "            test.loc[:, 'predicted'] = model.predict(test[f_set])\n",
    "            corr += pearsonr(test['gs'], test['predicted'])[0]\n",
    "        print(f_name, t_name, corr / N_ITERS, '(with surprise files)')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Is it possible to predict separating by source file?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy in predicting file: 0.8249106687085248\n",
      "[2 2 2 ... 0 0 0]\n",
      "Number of rows in partition  0 : 750\n",
      "One model\n",
      "Fitting 5 folds for each of 96 candidates, totalling 480 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\projects\\MAI\\IHLT\\Intro-to-IHLT-Labs\\.venv\\Lib\\site-packages\\numpy\\ma\\core.py:2846: RuntimeWarning: invalid value encountered in cast\n",
      "  _data = np.array(data, dtype=dtype, copy=copy,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Hyperparameters: {'bootstrap': True, 'max_depth': None, 'max_features': 'sqrt', 'min_samples_leaf': 1, 'min_samples_split': 2, 'n_estimators': 200}\n",
      "Number of rows in partition  1 : 750\n",
      "One model\n",
      "Fitting 5 folds for each of 96 candidates, totalling 480 fits\n",
      "Best Hyperparameters: {'bootstrap': True, 'max_depth': None, 'max_features': 'sqrt', 'min_samples_leaf': 2, 'min_samples_split': 2, 'n_estimators': 300}\n",
      "Number of rows in partition  2 : 734\n",
      "One model\n",
      "Fitting 5 folds for each of 96 candidates, totalling 480 fits\n",
      "Best Hyperparameters: {'bootstrap': True, 'max_depth': 10, 'max_features': 'sqrt', 'min_samples_leaf': 1, 'min_samples_split': 2, 'n_estimators': 100}\n",
      "Predicted len:  1454\n",
      "Predicted len:  1354\n",
      "Predicted len:  300\n",
      "Final correlation:  0.7283554075731684\n"
     ]
    }
   ],
   "source": [
    "from keras.utils import to_categorical\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "# Get a filtered test set\n",
    "filt_df_test = df_test[df_test['file'].isin(all_train_files)].copy()\n",
    "\n",
    "# Encode the file column to numerical labels\n",
    "label_encoder = LabelEncoder()\n",
    "df_train['file_encoded'] = label_encoder.fit_transform(df_train['file'])\n",
    "filt_df_test.loc[:, 'file_encoded'] = label_encoder.transform(filt_df_test['file'])\n",
    "\n",
    "# On the train set, do a categorical encoding for the file column\n",
    "y_train = to_categorical(df_train['file_encoded'], num_classes=len(all_train_files))\n",
    "# Filter the test dataset and do the categorical encoding\n",
    "filt_y_test = to_categorical(filt_df_test['file_encoded'], num_classes=len(all_train_files))\n",
    "\n",
    "# Create a random forest classification model from df_train to y_train\n",
    "clf = RandomForestClassifier(n_estimators=100)\n",
    "\n",
    "# Train the model\n",
    "clf.fit(df_train[all_features], y_train)\n",
    "\n",
    "# Predict on the test set\n",
    "y_pred = clf.predict(filt_df_test[all_features])\n",
    "\n",
    "# Evaluate the model\n",
    "accuracy = np.mean(np.argmax(filt_y_test, axis=1) == np.argmax(y_pred, axis=1))\n",
    "print('Accuracy in predicting file:', accuracy)\n",
    "\n",
    "# In the global train_set, assign the predicted file class\n",
    "print(np.argmax(clf.predict(df_train[all_features]), axis=1))\n",
    "df_train['pred_file'] = np.argmax(clf.predict(df_train[all_features]), axis=1)\n",
    "\n",
    "# Train a regression random forest for each partition of df_train based on pred_file\n",
    "partitioned_models = []\n",
    "for file_class in range(len(all_train_files)):\n",
    "    partition = df_train[df_train['pred_file']== file_class]\n",
    "    print(\"Number of rows in partition \", file_class, \":\", partition.shape[0])\n",
    "    if not partition.empty:\n",
    "        print(\"One model\")\n",
    "        model, params = train_RF(partition, all_features, 'gs')\n",
    "        # model = RandomForestRegressor(**params)\n",
    "        # model.fit(partition[all_features], partition['gs'])\n",
    "        partitioned_models.append(model)\n",
    "\n",
    "# For each row in df_test, predict the file class and use the corresponding model to predict the predicted_gs\n",
    "# Predict the file class for each row in df_test\n",
    "df_test['pred_file'] = np.argmax(clf.predict(df_test[all_features]), axis=1)\n",
    "\n",
    "# For each partition of df_test based on pred_file, use the corresponding model to predict the gs\n",
    "for fcls in range(len(all_train_files)):\n",
    "    pred_gs = partitioned_models[fcls].predict(df_test[df_test['pred_file'] == fcls][all_features])\n",
    "    print(\"Predicted len: \", len(pred_gs))\n",
    "    df_test.loc[df_test['pred_file'] == fcls, 'gs_predicted'] = pred_gs\n",
    "\n",
    "# Compute the pearson correlation\n",
    "final_corr = pearsonr(df_test['gs'], df_test['gs_predicted'])[0]\n",
    "print(\"Final correlation: \", final_corr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Result Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Result analysis to go here. This could go into a separate file (notebook or .md file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Conclusion to go here. This could go into a separate file (notebook or .md file)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
