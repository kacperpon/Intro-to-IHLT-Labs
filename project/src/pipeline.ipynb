{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Semantic Textual Similarity Project\n",
    "\n",
    "**Authors**\n",
    "- Kacper Poniatowski\n",
    "- Pau Blanco\n",
    "\n",
    "TODO: Include brief outline of project\n",
    "- Context\n",
    "- What were trying to achieve\n",
    "- etc."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pre-Reqs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\paubl\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package averaged_perceptron_tagger_eng to\n",
      "[nltk_data]     C:\\Users\\paubl\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package averaged_perceptron_tagger_eng is already up-to-\n",
      "[nltk_data]       date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\paubl\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package punkt_tab to\n",
      "[nltk_data]     C:\\Users\\paubl\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt_tab is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\paubl\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet_ic to\n",
      "[nltk_data]     C:\\Users\\paubl\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet_ic is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Force auto-reload\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import pandas as pd\n",
    "import nltk\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "from scipy.stats import pearsonr\n",
    "from utils import load_data\n",
    "from models import ModelTrainer\n",
    "from feature_extraction import FeatureExtractor\n",
    "from utils import save_predictions\n",
    "\n",
    "nltk.download('punkt')\n",
    "nltk.download('averaged_perceptron_tagger_eng')\n",
    "nltk.download('wordnet')\n",
    "nltk.download('punkt_tab')\n",
    "nltk.download('stopwords')\n",
    "nltk.download('wordnet_ic')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define Constants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define constant paths used throughout notebook\n",
    "TRAIN_PATH = '../data/train/01_raw/'\n",
    "TRAIN_GS_PATH = '../data/train/scores/'\n",
    "TEST_PATH = '../data/test/01_raw/'\n",
    "TEST_GS_PATH = '../data/test/scores/'\n",
    "TRAIN_SAVE_PATH = '../data/train/02_preprocessed/preprocessed_train_data.csv'\n",
    "TEST_SAVE_PATH = '../data/test/02_preprocessed/preprocessed_test_data.csv'\n",
    "PREDICTED_SAVE_PATH = '../data/test/03_predicted/'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Loading train data\n",
      "\n",
      " Loading test data\n",
      "\n",
      " Train and test datasets loaded successfully\n"
     ]
    }
   ],
   "source": [
    "# Load train data\n",
    "print('\\n Loading train data')\n",
    "all_train_files = ['SMTeuroparl', 'MSRvid', 'MSRpar']\n",
    "df_train = load_data(TRAIN_PATH, TRAIN_GS_PATH, all_train_files)\n",
    "\n",
    "# Load test data\n",
    "print('\\n Loading test data')\n",
    "all_test_files = ['SMTeuroparl', 'MSRvid', 'MSRpar', 'surprise.OnWN', 'surprise.SMTnews']\n",
    "df_test = load_data(TEST_PATH, TEST_GS_PATH, all_test_files)\n",
    "\n",
    "print('\\n Train and test datasets loaded successfully')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extract Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adding POS based features...\n",
      "Adding synset-based features...\n",
      "Processed 2233 of 2234 rows (100%)      \n",
      "Adding lemma based features...\n",
      "Adding POS based features...\n",
      "Adding synset-based features...\n",
      "Processed 3107 of 3108 rows (100%)      \n",
      "Adding lemma based features...\n",
      "\n",
      " Features added to datasets successfully\n",
      "\n",
      " Train and test datasets saved as .csv files successfully\n"
     ]
    }
   ],
   "source": [
    "feature_extractor = FeatureExtractor()\n",
    "\n",
    "# Extract the desired features\n",
    "def add_features(dt):\n",
    "    feature_extractor.add_POS_statistics(dt)\n",
    "    feature_extractor.add_synset_statistics(dt)\n",
    "    feature_extractor.add_lemma_statistics(dt)\n",
    "\n",
    "# Add features to the training and test data\n",
    "add_features(df_train)\n",
    "add_features(df_test)\n",
    "\n",
    "print('\\n Features added to datasets successfully')\n",
    "\n",
    "# Save df_train and df_test to respective files - this is done to avoid re-running the\n",
    "# feature extraction process each time as synset extraction is computationally expensive\n",
    "df_test.to_csv(TEST_SAVE_PATH, index=False)\n",
    "df_train.to_csv(TRAIN_SAVE_PATH, index=False)\n",
    "\n",
    "print('\\n Train and test datasets saved as .csv files successfully')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Score Calculation (Main Exercise)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Existing Dataframes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Train and test datasets loaded from .csv files successfully\n"
     ]
    }
   ],
   "source": [
    "if TRAIN_SAVE_PATH is None or TEST_SAVE_PATH is None:\n",
    "    raise ValueError('TRAIN_SAVE_PATH and TEST_SAVE_PATH must be defined')\n",
    "\n",
    "if not os.path.exists(TRAIN_SAVE_PATH):\n",
    "    raise FileNotFoundError(f'The file {TRAIN_SAVE_PATH} does not exist')\n",
    "\n",
    "if not os.path.exists(TEST_SAVE_PATH):\n",
    "    raise FileNotFoundError(f'The file {TEST_SAVE_PATH} does not exist')\n",
    "\n",
    "df_train = pd.read_csv(TRAIN_SAVE_PATH)\n",
    "df_test = pd.read_csv(TEST_SAVE_PATH)\n",
    "\n",
    "print('\\n Train and test datasets loaded from .csv files successfully')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define Features to Use in Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "lexical_features = [\n",
    "            # Lexical Word and POS Counts\n",
    "            's1_n_words', 's1_n_verbs_tot', 's1_n_verbs_pres', 's1_n_verbs_past', 's1_n_nouns', 's1_n_adjectives', 's1_n_adverbs', \n",
    "            's2_n_words', 's2_n_verbs_tot', 's2_n_verbs_pres', 's2_n_verbs_past', 's2_n_nouns', 's2_n_adjectives', 's2_n_adverbs', \n",
    "            'dif_n_words', 'dif_n_verbs_tot', 'dif_n_verbs_pres', 'dif_n_verbs_past', 'dif_n_nouns', 'dif_n_adjectives', 'dif_n_adverbs', \n",
    "\n",
    "            # Lexical Similarity\n",
    "            'jaccard_all_words', 'jaccard_verbs', 'jaccard_nouns', 'jaccard_adjectives', 'jaccard_adverbs',\n",
    "]\n",
    "\n",
    "semantic_features = [\n",
    "            # Semantic Synset and Synset Similarity\n",
    "            'all_all_shared_synsets_count', 'all_all_shared_synsets_ratio', 'all_all_avg_synset_similarity', 'all_all_max_synset_similarity',\n",
    "            'all_verb_shared_synsets_count', 'all_verb_shared_synsets_ratio', 'all_verb_avg_synset_similarity', 'all_verb_max_synset_similarity',\n",
    "            'all_noun_shared_synsets_count', 'all_noun_shared_synsets_ratio', 'all_noun_avg_synset_similarity', 'all_noun_max_synset_similarity',\n",
    "            'all_adj_shared_synsets_count', 'all_adj_shared_synsets_ratio', 'all_adj_avg_synset_similarity', 'all_adj_max_synset_similarity',\n",
    "            'all_adv_shared_synsets_count', 'all_adv_shared_synsets_ratio', 'all_adv_avg_synset_similarity', 'all_adv_max_synset_similarity',\n",
    "\n",
    "            # Semantic Best Matches (Optimized Synsets):\n",
    "            'best_all_shared_synsets_count', 'best_all_shared_synsets_ratio', 'best_all_avg_synset_similarity', 'best_all_max_synset_similarity',\n",
    "            'best_verb_shared_synsets_count', 'best_verb_shared_synsets_ratio', 'best_verb_avg_synset_similarity', 'best_verb_max_synset_similarity',\n",
    "            'best_noun_shared_synsets_count', 'best_noun_shared_synsets_ratio', 'best_noun_avg_synset_similarity', 'best_noun_max_synset_similarity',\n",
    "            'best_adj_shared_synsets_count', 'best_adj_shared_synsets_ratio', 'best_adj_avg_synset_similarity', 'best_adj_max_synset_similarity',\n",
    "            'best_adv_shared_synsets_count', 'best_adv_shared_synsets_ratio', 'best_adv_avg_synset_similarity', 'best_adv_max_synset_similarity',\n",
    "]\n",
    "\n",
    "syntactic_features = [\n",
    "            # Syntactic Features\n",
    "            'lemma_diversity', 'shared_lemmas_ratio', 'avg_lemma_similarity', 'max_lemma_similarity', 'shared_lemma_count', 'dice_coefficient',\n",
    "            'lemma_bigram_overlap', 'lemma_lcs_length', 'lemma_edit_distance', 'proportion_s1_in_s2', 'proportion_s2_in_s1', 'lemma_position_similarity'\n",
    "]\n",
    "\n",
    "all_features = lexical_features + semantic_features + syntactic_features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Initialise Model Trainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_trainer = ModelTrainer()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Perform on NN Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 8 candidates, totalling 24 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Kacpe\\Desktop\\College Work\\Repos\\Intro to HLT\\Work\\Labs\\project\\venv\\Lib\\site-packages\\keras\\src\\layers\\core\\dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Parameters: {'batch_size': 16, 'epochs': 100, 'model__hidden_layers': 2, 'model__learning_rate': 0.001, 'model__neurons': 10}\n",
      "\n",
      " Pearson correlation for the best NN model: 0.6483026019106067\n",
      "Predicted data saved to CSV: ../data/test/03_predicted/2024-12-09_11-03-45_predicted_nn_predicted_test_data.csv\n",
      "Predicted data saved to Excel: ../data/test/03_predicted/2024-12-09_11-03-45_predicted_nn_predicted_test_data.xlsx\n"
     ]
    }
   ],
   "source": [
    "best_nn_model = model_trainer.train_NN(df_train, all_features, 'gs')\n",
    "\n",
    "# TODO: Plot the training history (or something like this - we need statistics)\n",
    "#best_nn_model.plot_history()\n",
    "\n",
    "# Predict the test data\n",
    "df_test['predicted_nn'] = best_nn_model.predict(df_test[all_features])\n",
    "\n",
    "# Calculate the Pearson correlation\n",
    "correlation_nn = pearsonr(df_test['gs'], df_test['predicted_nn'])[0]\n",
    "print(f'\\n Pearson correlation for the best NN model: {correlation_nn}')\n",
    "\n",
    "# Save the predictions\n",
    "save_predictions(df_test, PREDICTED_SAVE_PATH, 'predicted_nn')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Perform on RF Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 96 candidates, totalling 480 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\projects\\MAI\\IHLT\\Intro-to-IHLT-Labs\\.venv\\Lib\\site-packages\\numpy\\ma\\core.py:2846: RuntimeWarning: invalid value encountered in cast\n",
      "  _data = np.array(data, dtype=dtype, copy=copy,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Hyperparameters: {'bootstrap': False, 'max_depth': None, 'max_features': 'sqrt', 'min_samples_leaf': 1, 'min_samples_split': 2, 'n_estimators': 300}\n",
      "\n",
      " Pearson correlation for the best RF model: 0.755781278357736\n",
      "Predicted data saved to CSV: ../data/test/03_predicted/2024-12-09_20-27-37_predicted_rf_predicted_test_data.csv\n",
      "Predicted data saved to Excel: ../data/test/03_predicted/2024-12-09_20-27-37_predicted_rf_predicted_test_data.xlsx\n",
      "Computing mean Pearson correlation for 10 iterations...\n",
      "Mean Pearson correlation: 0.7552431439444272\n"
     ]
    }
   ],
   "source": [
    "best_rf_model, params = model_trainer.train_RF(df_train, all_features, 'gs')\n",
    "\n",
    "# Plot the training history\n",
    "#best_rf_model.plot_history()\n",
    "\n",
    "# Predict the test data\n",
    "df_test['predicted_rf'] = best_rf_model.predict(df_test[all_features])\n",
    "\n",
    "# Calculate the Pearson correlation\n",
    "correlation_rf = pearsonr(df_test['gs'], df_test['predicted_rf'])[0]\n",
    "print(f'\\n Pearson correlation for the best RF model: {correlation_rf}')\n",
    "\n",
    "# Save the predictions to a file\n",
    "save_predictions(df_test, PREDICTED_SAVE_PATH, 'predicted_rf')\n",
    "\n",
    "# Best params found so far. Comment out if you want to use the params found in the grid search\n",
    "params =  {'bootstrap': False, 'max_depth': None, 'max_features': 'sqrt', 'min_samples_leaf': 1, 'min_samples_split': 2, 'n_estimators': 300}\n",
    "N_ITERS = 10\n",
    "corr = 0\n",
    "\n",
    "print(f\"Computing mean Pearson correlation for {N_ITERS} iterations...\")\n",
    "for i in range(N_ITERS):\n",
    "    model = model_trainer.train_single_RF(df_train, all_features, 'gs', params)\n",
    "    df_test['predicted'] = model.predict(df_test[all_features])\n",
    "    corr += pearsonr(df_test['gs'], df_test['predicted'])[0]\n",
    "    \n",
    "# print('NN Pearson correlation:', nn_p/N_ITERS)\n",
    "print('Mean Pearson correlation:', corr/N_ITERS)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Perform on SVR Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_svr_model = model_trainer.train_SVR(df_train, all_features, 'gs')\n",
    "\n",
    "# Plot the training history\n",
    "#best_svr_model.plot_history() # From data_analysis.ipynb CHANGE TO PY PROBABLY\n",
    "\n",
    "# Predict the test data\n",
    "df_test['predicted_svr'] = best_svr_model.predict(df_test[all_features])\n",
    "\n",
    "# Calculate the Pearson correlation\n",
    "correlation_svr = pearsonr(df_test['gs'], df_test['predicted_svr'])[0]\n",
    "print(f'\\n Pearson correlation for the best SVR model: {correlation_svr}')\n",
    "\n",
    "# Save the predictions to a file\n",
    "save_predictions(df_test, PREDICTED_SAVE_PATH, 'predicted_svr')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Perform on MLP Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 144 candidates, totalling 720 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Kacpe\\Desktop\\College Work\\Repos\\Intro to HLT\\Work\\Labs\\project\\venv\\Lib\\site-packages\\numpy\\ma\\core.py:2846: RuntimeWarning: invalid value encountered in cast\n",
      "  _data = np.array(data, dtype=dtype, copy=copy,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Hyperparameters: {'activation': 'tanh', 'alpha': 0.01, 'hidden_layer_sizes': (100,), 'learning_rate': 'adaptive', 'max_iter': 200, 'solver': 'adam'}\n",
      "\n",
      " Pearson correlation for the best MLP model: 0.6985481444114352\n",
      "Predicted data saved to CSV: ../data/test/03_predicted/2024-12-08_21-54-08_predicted_mlp_predicted_test_data.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Kacpe\\Desktop\\College Work\\Repos\\Intro to HLT\\Work\\Labs\\project\\src\\utils.py:54: FutureWarning: DataFrame.applymap has been deprecated. Use DataFrame.map instead.\n",
      "  return df.applymap(clean_value)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted data saved to Excel: ../data/test/03_predicted/2024-12-08_21-54-08_predicted_mlp_predicted_test_data.xlsx\n"
     ]
    }
   ],
   "source": [
    "best_mlp_model = model_trainer.train_MLP(df_train, all_features, 'gs')\n",
    "\n",
    "# Plot the training history\n",
    "#best_mlp_model.plot_history()\n",
    "\n",
    "# Predict the test data\n",
    "df_test['predicted_mlp'] = best_mlp_model.predict(df_test[all_features])\n",
    "\n",
    "# Calculate the Pearson correlation\n",
    "correlation_mlp = pearsonr(df_test['gs'], df_test['predicted_mlp'])[0]\n",
    "print(f'\\n Pearson correlation for the best MLP model: {correlation_mlp}')\n",
    "\n",
    "# Save the predictions to a file\n",
    "save_predictions(df_test, PREDICTED_SAVE_PATH, 'predicted_mlp')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Additional Code (TODO: Review what we need from this in final submission)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# To use the best params found so far:\n",
    "params = {'bootstrap': False, 'max_depth': None, 'max_features': 'sqrt', 'min_samples_leaf': 1, 'min_samples_split': 2, 'n_estimators': 300} "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 RF Pearson correlation: 0.7544972344580401 => 0.7544972344580401\n",
      "1 RF Pearson correlation: 0.7535936296433925 => 0.7540454320507163\n",
      "2 RF Pearson correlation: 0.7537330174239986 => 0.7539412938418103\n",
      "3 RF Pearson correlation: 0.7546805056402872 => 0.7541260967914296\n",
      "4 RF Pearson correlation: 0.753344841863264 => 0.7539698458057964\n",
      "5 RF Pearson correlation: 0.7540238942223967 => 0.7539788538752298\n",
      "6 RF Pearson correlation: 0.7553757141035773 => 0.7541784053364223\n",
      "7 RF Pearson correlation: 0.7533933285715921 => 0.7540802707408185\n",
      "8 RF Pearson correlation: 0.7543458798205056 => 0.7541097828607837\n",
      "9 RF Pearson correlation: 0.7539957688991203 => 0.7540983814646174\n",
      "Mean RF Pearson correlation: 0.7540983814646174\n"
     ]
    }
   ],
   "source": [
    "N_ITERS = 10\n",
    "rf_p = 0\n",
    "\n",
    "for i in range(N_ITERS):\n",
    "    # print('Iteration:', i)\n",
    "    # hist, model = train_NN(df, features, 'gs')\n",
    "    # df_test['predicted'] = model.predict(df_test[features])\n",
    "    # corr = pearsonr(df_test['gs'], df_test['predicted'])[0]\n",
    "    # print('NN Pearson correlation:', corr)\n",
    "    # nn_p += corr\n",
    "\n",
    "    model = train_single_RF(df_train, all_features, 'gs', params)\n",
    "    df_test['predicted'] = model.predict(df_test[all_features])\n",
    "    corr = pearsonr(df_test['gs'], df_test['predicted'])[0]\n",
    "    rf_p += corr\n",
    "    print(i, 'RF Pearson correlation:', corr, \"=>\", rf_p/(i+1))\n",
    "\n",
    "# print('NN Pearson correlation:', nn_p/N_ITERS)\n",
    "print('Mean RF Pearson correlation:', rf_p/N_ITERS)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compare correlation based on file and features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "All SMTeuroparl 0.5260762425283135\n",
      "All SMTeuroparl 0.6321408221170948 (with surprise files)\n",
      "Synsets SMTeuroparl 0.5089847580757192\n",
      "Synsets SMTeuroparl 0.5984333819281736 (with surprise files)\n",
      "Lemmas SMTeuroparl 0.48728005311908856\n",
      "Lemmas SMTeuroparl 0.5838403729608709 (with surprise files)\n",
      "PoS (Syntactical) SMTeuroparl 0.28082396513890506\n",
      "PoS (Syntactical) SMTeuroparl 0.3062866488678532 (with surprise files)\n",
      "Lexical SMTeuroparl 0.5317844394052379\n",
      "Lexical SMTeuroparl 0.6256457418945189 (with surprise files)\n",
      "\n",
      "All MSRvid 0.8611804247098516\n",
      "All MSRvid 0.7915275196347473 (with surprise files)\n",
      "Synsets MSRvid 0.8597524788987414\n",
      "Synsets MSRvid 0.7654246344934643 (with surprise files)\n",
      "Lemmas MSRvid 0.6572899927033499\n",
      "Lemmas MSRvid 0.6420521699471147 (with surprise files)\n",
      "PoS (Syntactical) MSRvid 0.20808034566065797\n",
      "PoS (Syntactical) MSRvid 0.35248343346031863 (with surprise files)\n",
      "Lexical MSRvid 0.8620913345693634\n",
      "Lexical MSRvid 0.7776658207000915 (with surprise files)\n",
      "\n",
      "All MSRpar 0.5980055133354054\n",
      "All MSRpar 0.5228975085251519 (with surprise files)\n",
      "Synsets MSRpar 0.5177578550169951\n",
      "Synsets MSRpar 0.4476150310809409 (with surprise files)\n",
      "Lemmas MSRpar 0.5530242136102264\n",
      "Lemmas MSRpar 0.5424651769788617 (with surprise files)\n",
      "PoS (Syntactical) MSRpar 0.3351401615843118\n",
      "PoS (Syntactical) MSRpar 0.020682043233786286 (with surprise files)\n",
      "Lexical MSRpar 0.5900589694756582\n",
      "Lexical MSRpar 0.5382029182207234 (with surprise files)\n",
      "\n",
      "All All 0.8032769795343603\n",
      "All All 0.7541890174149117 (with surprise files)\n",
      "Synsets All 0.7835546046102503\n",
      "Synsets All 0.7242258621409416 (with surprise files)\n",
      "Lemmas All 0.6935845573569963\n",
      "Lemmas All 0.6414015564547721 (with surprise files)\n",
      "PoS (Syntactical) All 0.4763025071936748\n",
      "PoS (Syntactical) All 0.4546740328382729 (with surprise files)\n",
      "Lexical All 0.8032998452799843\n",
      "Lexical All 0.7456461981167642 (with surprise files)\n"
     ]
    }
   ],
   "source": [
    "all_features = [\n",
    "            's1_n_words', 's1_n_verbs_tot', 's1_n_verbs_pres', 's1_n_verbs_past', 's1_n_nouns', 's1_n_adjectives', 's1_n_adverbs', \n",
    "            's2_n_words', 's2_n_verbs_tot', 's2_n_verbs_pres', 's2_n_verbs_past', 's2_n_nouns', 's2_n_adjectives', 's2_n_adverbs', \n",
    "            'dif_n_words', 'dif_n_verbs_tot', 'dif_n_verbs_pres', 'dif_n_verbs_past', 'dif_n_nouns', 'dif_n_adjectives', 'dif_n_adverbs', \n",
    "            'jaccard_all_words', 'jaccard_verbs', 'jaccard_nouns', 'jaccard_adjectives', 'jaccard_adverbs',\n",
    "            \n",
    "            'all_all_shared_synsets_count', 'all_all_shared_synsets_ratio', 'all_all_avg_synset_similarity', 'all_all_max_synset_similarity',\n",
    "            'all_verb_shared_synsets_count', 'all_verb_shared_synsets_ratio', 'all_verb_avg_synset_similarity', 'all_verb_max_synset_similarity',\n",
    "            'all_noun_shared_synsets_count', 'all_noun_shared_synsets_ratio', 'all_noun_avg_synset_similarity', 'all_noun_max_synset_similarity',\n",
    "            'all_adj_shared_synsets_count', 'all_adj_shared_synsets_ratio', 'all_adj_avg_synset_similarity', 'all_adj_max_synset_similarity',\n",
    "            'all_adv_shared_synsets_count', 'all_adv_shared_synsets_ratio', 'all_adv_avg_synset_similarity', 'all_adv_max_synset_similarity',\n",
    "\n",
    "            'best_all_shared_synsets_count', 'best_all_shared_synsets_ratio', 'best_all_avg_synset_similarity', 'best_all_max_synset_similarity',\n",
    "            'best_verb_shared_synsets_count', 'best_verb_shared_synsets_ratio', 'best_verb_avg_synset_similarity', 'best_verb_max_synset_similarity',\n",
    "            'best_noun_shared_synsets_count', 'best_noun_shared_synsets_ratio', 'best_noun_avg_synset_similarity', 'best_noun_max_synset_similarity',\n",
    "            'best_adj_shared_synsets_count', 'best_adj_shared_synsets_ratio', 'best_adj_avg_synset_similarity', 'best_adj_max_synset_similarity',\n",
    "            'best_adv_shared_synsets_count', 'best_adv_shared_synsets_ratio', 'best_adv_avg_synset_similarity', 'best_adv_max_synset_similarity',\n",
    "\n",
    "            'lemma_diversity', 'shared_lemmas_ratio', 'lemma_jackard_similarity', 'avg_lemma_similarity', 'max_lemma_similarity', 'shared_lemma_count', 'dice_coefficient',\n",
    "            'lemma_bigram_overlap', 'lemma_lcs_length', 'lemma_edit_distance', 'proportion_s1_in_s2', 'proportion_s2_in_s1', 'lemma_position_similarity'\n",
    "            ]\n",
    "PoS_features = [\n",
    "            's1_n_words', 's1_n_verbs_tot', 's1_n_verbs_pres', 's1_n_verbs_past', 's1_n_nouns', 's1_n_adjectives', 's1_n_adverbs', \n",
    "            's2_n_words', 's2_n_verbs_tot', 's2_n_verbs_pres', 's2_n_verbs_past', 's2_n_nouns', 's2_n_adjectives', 's2_n_adverbs', \n",
    "            'dif_n_words', 'dif_n_verbs_tot', 'dif_n_verbs_pres', 'dif_n_verbs_past', 'dif_n_nouns', 'dif_n_adjectives', 'dif_n_adverbs', \n",
    "            'jaccard_all_words', 'jaccard_verbs', 'jaccard_nouns', 'jaccard_adjectives', 'jaccard_adverbs',\n",
    "            ]\n",
    "synset_features = [\n",
    "            'all_all_shared_synsets_count', 'all_all_shared_synsets_ratio', 'all_all_avg_synset_similarity', 'all_all_max_synset_similarity',\n",
    "            'all_verb_shared_synsets_count', 'all_verb_shared_synsets_ratio', 'all_verb_avg_synset_similarity', 'all_verb_max_synset_similarity',\n",
    "            'all_noun_shared_synsets_count', 'all_noun_shared_synsets_ratio', 'all_noun_avg_synset_similarity', 'all_noun_max_synset_similarity',\n",
    "            'all_adj_shared_synsets_count', 'all_adj_shared_synsets_ratio', 'all_adj_avg_synset_similarity', 'all_adj_max_synset_similarity',\n",
    "            'all_adv_shared_synsets_count', 'all_adv_shared_synsets_ratio', 'all_adv_avg_synset_similarity', 'all_adv_max_synset_similarity',\n",
    "\n",
    "            'best_all_shared_synsets_count', 'best_all_shared_synsets_ratio', 'best_all_avg_synset_similarity', 'best_all_max_synset_similarity',\n",
    "            'best_verb_shared_synsets_count', 'best_verb_shared_synsets_ratio', 'best_verb_avg_synset_similarity', 'best_verb_max_synset_similarity',\n",
    "            'best_noun_shared_synsets_count', 'best_noun_shared_synsets_ratio', 'best_noun_avg_synset_similarity', 'best_noun_max_synset_similarity',\n",
    "            'best_adj_shared_synsets_count', 'best_adj_shared_synsets_ratio', 'best_adj_avg_synset_similarity', 'best_adj_max_synset_similarity',\n",
    "            'best_adv_shared_synsets_count', 'best_adv_shared_synsets_ratio', 'best_adv_avg_synset_similarity', 'best_adv_max_synset_similarity',\n",
    "            ]\n",
    "lemma_features = [\n",
    "            'lemma_diversity', 'shared_lemmas_ratio', 'lemma_jackard_similarity', 'avg_lemma_similarity', 'max_lemma_similarity', 'shared_lemma_count', 'dice_coefficient',\n",
    "            'lemma_bigram_overlap', 'lemma_lcs_length', 'lemma_edit_distance', 'proportion_s1_in_s2', 'proportion_s2_in_s1', 'lemma_position_similarity'\n",
    "            ]\n",
    "lexical_features = [\n",
    "            'all_all_shared_synsets_count', 'all_all_shared_synsets_ratio', 'all_all_avg_synset_similarity', 'all_all_max_synset_similarity',\n",
    "            'all_verb_shared_synsets_count', 'all_verb_shared_synsets_ratio', 'all_verb_avg_synset_similarity', 'all_verb_max_synset_similarity',\n",
    "            'all_noun_shared_synsets_count', 'all_noun_shared_synsets_ratio', 'all_noun_avg_synset_similarity', 'all_noun_max_synset_similarity',\n",
    "            'all_adj_shared_synsets_count', 'all_adj_shared_synsets_ratio', 'all_adj_avg_synset_similarity', 'all_adj_max_synset_similarity',\n",
    "            'all_adv_shared_synsets_count', 'all_adv_shared_synsets_ratio', 'all_adv_avg_synset_similarity', 'all_adv_max_synset_similarity',\n",
    "\n",
    "            'best_all_shared_synsets_count', 'best_all_shared_synsets_ratio', 'best_all_avg_synset_similarity', 'best_all_max_synset_similarity',\n",
    "            'best_verb_shared_synsets_count', 'best_verb_shared_synsets_ratio', 'best_verb_avg_synset_similarity', 'best_verb_max_synset_similarity',\n",
    "            'best_noun_shared_synsets_count', 'best_noun_shared_synsets_ratio', 'best_noun_avg_synset_similarity', 'best_noun_max_synset_similarity',\n",
    "            'best_adj_shared_synsets_count', 'best_adj_shared_synsets_ratio', 'best_adj_avg_synset_similarity', 'best_adj_max_synset_similarity',\n",
    "            'best_adv_shared_synsets_count', 'best_adv_shared_synsets_ratio', 'best_adv_avg_synset_similarity', 'best_adv_max_synset_similarity',\n",
    "\n",
    "            'lemma_diversity', 'shared_lemmas_ratio', 'lemma_jackard_similarity', 'avg_lemma_similarity', 'max_lemma_similarity', 'shared_lemma_count', 'dice_coefficient',\n",
    "            'lemma_bigram_overlap', 'lemma_lcs_length', 'lemma_edit_distance', 'proportion_s1_in_s2', 'proportion_s2_in_s1', 'lemma_position_similarity'\n",
    "]\n",
    "features_sets = [('All', all_features), ('Synsets', synset_features), ('Lemmas', lemma_features), ('PoS (Syntactical)', PoS_features), ('Lexical', lexical_features), ]\n",
    "files_sets = [\n",
    "    ('SMTeuroparl', ['SMTeuroparl'], ['SMTeuroparl', 'surprise.OnWN', 'surprise.SMTnews']),\n",
    "    ('MSRvid', ['MSRvid'], ['MSRvid', 'surprise.OnWN', 'surprise.SMTnews']),\n",
    "    ('MSRpar', ['MSRpar'], ['MSRpar', 'surprise.OnWN', 'surprise.SMTnews']),\n",
    "    ('All', ['SMTeuroparl', 'MSRvid', 'MSRpar'], ['SMTeuroparl', 'MSRvid', 'MSRpar', 'surprise.OnWN', 'surprise.SMTnews'])\n",
    "]\n",
    "\n",
    "N_ITERS = 10\n",
    "# Train a Random Forest for each feature set and each file set\n",
    "for t_name, tr_set, vl_set in files_sets:\n",
    "    print()\n",
    "    for f_name, f_set in features_sets:\n",
    "        train = df_train[df_train['file'].isin(tr_set)]\n",
    "        \n",
    "        test = df_test[df_test['file'].isin(tr_set)]\n",
    "        corr = 0\n",
    "        for i in range(N_ITERS):\n",
    "            model = train_single_RF(train, f_set, 'gs', params)\n",
    "            test.loc[:, 'predicted'] = model.predict(test[f_set])\n",
    "            corr += pearsonr(test['gs'], test['predicted'])[0]\n",
    "        print(f_name, t_name, corr / N_ITERS)\n",
    "\n",
    "        test = df_test[df_test['file'].isin(vl_set)]\n",
    "        corr = 0\n",
    "        for i in range(N_ITERS):\n",
    "            model = train_single_RF(train, f_set, 'gs', params)\n",
    "            test.loc[:, 'predicted'] = model.predict(test[f_set])\n",
    "            corr += pearsonr(test['gs'], test['predicted'])[0]\n",
    "        print(f_name, t_name, corr / N_ITERS, '(with surprise files)')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Is it possible to predict separating by source file?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy in predicting file: 0.8249106687085248\n",
      "[2 2 2 ... 0 0 0]\n",
      "Number of rows in partition  0 : 750\n",
      "One model\n",
      "Fitting 5 folds for each of 96 candidates, totalling 480 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\projects\\MAI\\IHLT\\Intro-to-IHLT-Labs\\.venv\\Lib\\site-packages\\numpy\\ma\\core.py:2846: RuntimeWarning: invalid value encountered in cast\n",
      "  _data = np.array(data, dtype=dtype, copy=copy,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Hyperparameters: {'bootstrap': True, 'max_depth': None, 'max_features': 'sqrt', 'min_samples_leaf': 1, 'min_samples_split': 2, 'n_estimators': 200}\n",
      "Number of rows in partition  1 : 750\n",
      "One model\n",
      "Fitting 5 folds for each of 96 candidates, totalling 480 fits\n",
      "Best Hyperparameters: {'bootstrap': True, 'max_depth': None, 'max_features': 'sqrt', 'min_samples_leaf': 2, 'min_samples_split': 2, 'n_estimators': 300}\n",
      "Number of rows in partition  2 : 734\n",
      "One model\n",
      "Fitting 5 folds for each of 96 candidates, totalling 480 fits\n",
      "Best Hyperparameters: {'bootstrap': True, 'max_depth': 10, 'max_features': 'sqrt', 'min_samples_leaf': 1, 'min_samples_split': 2, 'n_estimators': 100}\n",
      "Predicted len:  1454\n",
      "Predicted len:  1354\n",
      "Predicted len:  300\n",
      "Final correlation:  0.7283554075731684\n"
     ]
    }
   ],
   "source": [
    "from keras.utils import to_categorical\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "# Get a filtered test set\n",
    "filt_df_test = df_test[df_test['file'].isin(all_train_files)].copy()\n",
    "\n",
    "# Encode the file column to numerical labels\n",
    "label_encoder = LabelEncoder()\n",
    "df_train['file_encoded'] = label_encoder.fit_transform(df_train['file'])\n",
    "filt_df_test.loc[:, 'file_encoded'] = label_encoder.transform(filt_df_test['file'])\n",
    "\n",
    "# On the train set, do a categorical encoding for the file column\n",
    "y_train = to_categorical(df_train['file_encoded'], num_classes=len(all_train_files))\n",
    "# Filter the test dataset and do the categorical encoding\n",
    "filt_y_test = to_categorical(filt_df_test['file_encoded'], num_classes=len(all_train_files))\n",
    "\n",
    "# Create a random forest classification model from df_train to y_train\n",
    "clf = RandomForestClassifier(n_estimators=100)\n",
    "\n",
    "# Train the model\n",
    "clf.fit(df_train[all_features], y_train)\n",
    "\n",
    "# Predict on the test set\n",
    "y_pred = clf.predict(filt_df_test[all_features])\n",
    "\n",
    "# Evaluate the model\n",
    "accuracy = np.mean(np.argmax(filt_y_test, axis=1) == np.argmax(y_pred, axis=1))\n",
    "print('Accuracy in predicting file:', accuracy)\n",
    "\n",
    "# In the global train_set, assign the predicted file classç\n",
    "print(np.argmax(clf.predict(df_train[all_features]), axis=1))\n",
    "df_train['pred_file'] = np.argmax(clf.predict(df_train[all_features]), axis=1)\n",
    "\n",
    "# Train a regression random forest for each partition of df_train based on pred_file\n",
    "partitioned_models = []\n",
    "for file_class in range(len(all_train_files)):\n",
    "    partition = df_train[df_train['pred_file']== file_class]\n",
    "    print(\"Number of rows in partition \", file_class, \":\", partition.shape[0])\n",
    "    if not partition.empty:\n",
    "        print(\"One model\")\n",
    "        model, params = train_RF(partition, all_features, 'gs')\n",
    "        # model = RandomForestRegressor(**params)\n",
    "        # model.fit(partition[all_features], partition['gs'])\n",
    "        partitioned_models.append(model)\n",
    "\n",
    "# For each row in df_test, predict the file class and use the corresponding model to predict the predicted_gs\n",
    "# Predict the file class for each row in df_test\n",
    "df_test['pred_file'] = np.argmax(clf.predict(df_test[all_features]), axis=1)\n",
    "\n",
    "# For each partition of df_test based on pred_file, use the corresponding model to predict the gs\n",
    "for fcls in range(len(all_train_files)):\n",
    "    pred_gs = partitioned_models[fcls].predict(df_test[df_test['pred_file'] == fcls][all_features])\n",
    "    print(\"Predicted len: \", len(pred_gs))\n",
    "    df_test.loc[df_test['pred_file'] == fcls, 'gs_predicted'] = pred_gs\n",
    "\n",
    "# Compute the pearson correlation\n",
    "final_corr = pearsonr(df_test['gs'], df_test['gs_predicted'])[0]\n",
    "print(\"Final correlation: \", final_corr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Result Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Result analysis to go here. This could go into a separate file (notebook or .md file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Conclusion to go here. This could go into a separate file (notebook or .md file)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
