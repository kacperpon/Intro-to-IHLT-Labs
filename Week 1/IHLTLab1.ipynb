{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[{"file_id":"1K8-kEj-OkkCYLzG-eYfPXXOgqii120nf","timestamp":1726504772225},{"file_id":"1PDr2k6MZoag3tsAY03mN-F51uBzqKgY2","timestamp":1726504680071}]},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","source":["# IHLT Lab Exercise 1\n","## This file contains code to complete the exercise for the first lab session of IHLT\n","Authors:\n","\n","\n","*   Kacper Poniatowski (kacper.krzysztof.poniatowski@estudiantat.upc.edu)\n","*   Pau Blanco (pablo.blanco@estudiantat.upc.edu)\n","\n","\n","\n","Statement:\n","\n","Develop a colab notebook that show the 25 non-stopwords with more number of occurrences in the file 'blake-poems.txt' of Gutenberg corpus."],"metadata":{"id":"EsahlW7_lBFY"}},{"cell_type":"code","execution_count":2,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"AnFV_Og8kduF","executionInfo":{"status":"ok","timestamp":1726643986862,"user_tz":-120,"elapsed":7030,"user":{"displayName":"Pablo Blanco Del Prado","userId":"02913114842217546842"}},"outputId":"087606e7-225f-4354-d592-8aa737d2ab71"},"outputs":[{"output_type":"stream","name":"stderr","text":["[nltk_data] Downloading package gutenberg to /root/nltk_data...\n","[nltk_data]   Unzipping corpora/gutenberg.zip.\n","[nltk_data] Downloading package stopwords to /root/nltk_data...\n","[nltk_data]   Unzipping corpora/stopwords.zip.\n"]}],"source":["import nltk\n","from nltk.corpus import gutenberg\n","from nltk.corpus import stopwords\n","\n","TOP_WORDS = 25\n","FILENAME = 'blake-poems.txt'\n","\n","nltk.download('gutenberg')\n","nltk.download('stopwords')\n","\n","stopwords = set(stopwords.words('english'))"]},{"cell_type":"code","source":["# load the specified file\n","wholeFile = gutenberg.words(FILENAME)\n","\n","print(\"Loaded file: \" + FILENAME)\n","print(\"Total words: \", len(wholeFile))"],"metadata":{"id":"7Qtmfw-RtDWH","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1726643990606,"user_tz":-120,"elapsed":447,"user":{"displayName":"Pablo Blanco Del Prado","userId":"02913114842217546842"}},"outputId":"14e1cfe5-b2c6-4a2a-a4ef-2f056f7a8562"},"execution_count":3,"outputs":[{"output_type":"stream","name":"stdout","text":["Loaded file: blake-poems.txt\n","Total words:  8354\n"]}]},{"cell_type":"code","source":["# Remove all stopwords and non-alphanumerics from file\n","words = [word.lower() for word in wholeFile if word.isalnum() and word.lower() not in stopwords]\n","\n","# Remove words containing only numbers\n","words = [word for word in words if not word.isdigit()]\n","\n","print(f\"Good words {len(words)} ({len(words) / len(wholeFile) * 100:.1f}%)\")"],"metadata":{"id":"mlm8uTf0tgiK","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1726644011217,"user_tz":-120,"elapsed":445,"user":{"displayName":"Pablo Blanco Del Prado","userId":"02913114842217546842"}},"outputId":"923a2aae-81e4-4240-b4e5-3c3afd16343c"},"execution_count":5,"outputs":[{"output_type":"stream","name":"stdout","text":["Good words 3805 (45.5%)\n"]}]},{"cell_type":"code","source":["# Prepare the freqs object\n","freqs = {}\n","\n","for w in words:\n","    if w in freqs:\n","        freqs[w] += 1\n","    else:\n","        freqs[w] = 1\n","\n","# Sort the freqs dict by highest frequency first\n","top_words = sorted(freqs.items(), key=lambda x: x[1], reverse=True)[:TOP_WORDS]\n","\n","# Print the top words and their frequencies\n","for word, freq in top_words:\n","    print(f\"{word}: {freq}\")"],"metadata":{"id":"kAW7KQqMtn3M","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1726644019163,"user_tz":-120,"elapsed":456,"user":{"displayName":"Pablo Blanco Del Prado","userId":"02913114842217546842"}},"outputId":"4198702b-9ed7-4839-d57c-802a2b5d847f"},"execution_count":6,"outputs":[{"output_type":"stream","name":"stdout","text":["little: 45\n","thee: 42\n","like: 35\n","thou: 35\n","thy: 31\n","love: 29\n","sweet: 28\n","night: 28\n","joy: 25\n","away: 24\n","weep: 24\n","father: 22\n","sleep: 21\n","happy: 19\n","shall: 19\n","day: 19\n","mother: 19\n","child: 18\n","every: 17\n","never: 17\n","thel: 16\n","hear: 16\n","green: 16\n","er: 16\n","voice: 16\n"]}]},{"cell_type":"markdown","source":["# Conclusions\n","This first exercise is quite simple, and only two points are worth mentioning.\n","\n","In the first test, where we read the words and removed the stop words, we realized that the top positions are occupied by punctuation marks. Therefore, we decided to filter the words returned by nltk to remove also punctuation marks and numbers.\n","\n","It is also worth mentioning that in positions 21 to 28 of the word ranking, all the words have 16 occurrences. Since no specific guideline was provided, the results truncate some words due to the 25-word limit."],"metadata":{"id":"tt296MrAoIt-"}}]}